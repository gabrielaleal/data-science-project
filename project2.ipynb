{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b4e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "import gc\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1747e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed_precision.set_global_policy('mixed_float16')\n",
    "# physical_devices = tf.config.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c781e0",
   "metadata": {},
   "source": [
    "## Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09fbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('project1_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a7c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll get a subset of our dataset in order to make experiments faster\n",
    "df = df[:1000]\n",
    "df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0bc65",
   "metadata": {},
   "source": [
    "#### Converting cols to their appropriate types again because we lost it on the csv export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fbdbe54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"product_category_name\"] = df[\"product_category_name\"].astype('category')\n",
    "df[\"order_status\"] = df[\"order_status\"].astype('category')\n",
    "df[\"review_score\"] = df[\"review_score\"].astype('category')\n",
    "df[\"payment_type\"] = df[\"payment_type\"].astype('category')\n",
    "df[\"customer_zip_code_prefix\"] = df[\"customer_zip_code_prefix\"].astype('category')\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype('category')\n",
    "df[\"customer_state\"] = df[\"customer_state\"].astype('category')\n",
    "df[\"seller_zip_code_prefix\"] = df[\"seller_zip_code_prefix\"].astype('category')\n",
    "df[\"seller_city\"] = df[\"seller_city\"].astype('category')\n",
    "df[\"seller_state\"] = df[\"seller_state\"].astype('category')\n",
    "\n",
    "df[\"product_name_lenght\"] = df[\"product_name_lenght\"].astype('int64')\n",
    "df[\"product_description_lenght\"] = df[\"product_description_lenght\"].astype('int64')\n",
    "df[\"product_photos_qty\"] = df[\"product_photos_qty\"].astype('int64')\n",
    "df[\"payment_installments\"] = df[\"payment_installments\"].astype('int64')\n",
    "df[\"payment_sequential\"] = df[\"payment_sequential\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076bef45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                           object\n",
       "order_item_id                       int64\n",
       "product_id                         object\n",
       "seller_id                          object\n",
       "shipping_limit_date                object\n",
       "price                             float64\n",
       "freight_value                     float64\n",
       "product_category_name            category\n",
       "product_name_lenght                 int64\n",
       "product_description_lenght          int64\n",
       "product_photos_qty                  int64\n",
       "product_weight_g                  float64\n",
       "product_length_cm                 float64\n",
       "product_height_cm                 float64\n",
       "product_width_cm                  float64\n",
       "customer_id                        object\n",
       "order_status                     category\n",
       "order_purchase_timestamp           object\n",
       "order_approved_at                  object\n",
       "order_delivered_carrier_date       object\n",
       "order_delivered_customer_date      object\n",
       "order_estimated_delivery_date      object\n",
       "review_id                          object\n",
       "review_score                     category\n",
       "review_creation_date               object\n",
       "review_answer_timestamp            object\n",
       "payment_sequential                  int64\n",
       "payment_type                     category\n",
       "payment_installments                int64\n",
       "payment_value                     float64\n",
       "customer_unique_id                 object\n",
       "customer_zip_code_prefix         category\n",
       "customer_city                    category\n",
       "customer_state                   category\n",
       "seller_zip_code_prefix           category\n",
       "seller_city                      category\n",
       "seller_state                     category\n",
       "payment_value_norm                float64\n",
       "payment_value_dist                 object\n",
       "volume                            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d661d06",
   "metadata": {},
   "source": [
    "#### Droping unnecessary columns\n",
    "We only want to work with numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0c918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839d9829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_item_id', 'price', 'freight_value', 'product_category_name',\n",
       "       'product_name_lenght', 'product_description_lenght',\n",
       "       'product_photos_qty', 'product_weight_g', 'product_length_cm',\n",
       "       'product_height_cm', 'product_width_cm', 'order_status', 'review_score',\n",
       "       'payment_sequential', 'payment_type', 'payment_installments',\n",
       "       'payment_value', 'customer_zip_code_prefix', 'customer_city',\n",
       "       'customer_state', 'seller_zip_code_prefix', 'seller_city',\n",
       "       'seller_state', 'payment_value_norm', 'volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095deda2",
   "metadata": {},
   "source": [
    "We'll also drop the `payment_value` column because our model would simply infer our target value from it by subtracting it from the `price` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee80e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['payment_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ade1c",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "Here we'll one-hot encode all of our categorical columns, and then drop the original ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888fbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df = df.select_dtypes(exclude=['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87163958",
   "metadata": {},
   "source": [
    "Even though we generated over 22000 columns this way, we believe that our model will be powerful enough to filter out any unecessary data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf542d7f",
   "metadata": {},
   "source": [
    "## Picking column for prediction\n",
    "\n",
    "We chose the `freight_value` column so we can perform a regression in order to try to find it's value based on all of the columns we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222e2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VALUE = 'freight_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b762581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = df[TARGET_VALUE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56b26f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      13.29\n",
       "1      19.93\n",
       "2      17.87\n",
       "3      12.79\n",
       "4      18.14\n",
       "       ...  \n",
       "995    74.99\n",
       "996    34.98\n",
       "997    17.03\n",
       "998    19.07\n",
       "999    15.59\n",
       "Name: freight_value, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67fb6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[TARGET_VALUE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005f0b8",
   "metadata": {},
   "source": [
    "## Separating prediction and test data\n",
    "\n",
    "We'll split our data in a 60/20/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "760b9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_data():\n",
    "    # input \n",
    "    train, val, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8c5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_data():\n",
    "    # output\n",
    "    train_labels, val_labels, test_labels = (\n",
    "        np.split(\n",
    "            target_col, \n",
    "            [int(.6*len(target_col)), int(.8*len(target_col))])\n",
    "    )\n",
    "    \n",
    "    return train_labels, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa6267b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting our initial df so we can free up some RAM\n",
    "# del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b17f0b",
   "metadata": {},
   "source": [
    "# Picking 4 ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3d0e6",
   "metadata": {},
   "source": [
    "We'll use the following 4 algorithms:\n",
    "\n",
    "1. Linear regression\n",
    "2. Multilayer perceptron (a shallow one)\n",
    "3. random forests\n",
    "4. lightgbm/xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647da00",
   "metadata": {},
   "source": [
    "### Metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1ac53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate metrics\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf643db6",
   "metadata": {},
   "source": [
    "### Enabling MLFlow autologging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc0517aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/08/15 23:34:25 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "mlflow.tensorflow.autolog()\n",
    "mlflow.lightgbm.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8160d9",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "Let's start off with linear regression, which is the most simple algorithm in our selection, and will serve as a baseline for the following algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82ba2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(trial):\n",
    "    train, test, val = get_x_data()\n",
    "    train_labels, val_labels, test_labels = get_y_data()\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "    with mlflow.start_run(run_name=\"Linear Regression\"):\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(train, train_labels)\n",
    "\n",
    "        predictions = reg.predict(val)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
    "\n",
    "        # Print out model metrics\n",
    "        print(\"Linear regression model\")\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log mlflow attributes for mlflow UI\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        #mlflow.sklearn.log_model(reg, \"model\")\n",
    "        #modelpath = \"./mlflow/freight_value/model-linear-reg\"\n",
    "        #mlflow.sklearn.save_model(reg, modelpath)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d3d27c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:25,954]\u001b[0m A new study created in memory with name: no-name-dab5cdf6-d3af-4a3d-bc5e-cd04a2250b40\u001b[0m\n",
      "\u001b[32m[I 2021-08-15 23:34:26,940]\u001b[0m Trial 0 finished with value: 90.99431207401365 and parameters: {}. Best is trial 0 with value: 90.99431207401365.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model\n",
      "  RMSE: 90.99431207401365\n",
      "  MAE: 65.309461906497\n",
      "  R2: -38.3482098714733\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(linear_regression, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a6d6a",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac5dfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(trial):\n",
    "    train, test, val = get_x_data()\n",
    "    train_labels, val_labels, test_labels = get_y_data()\n",
    "    \n",
    "    # hyper-parameters to test\n",
    "    params = {\n",
    "        \"hidden_units\": trial.suggest_int(\"hidden_units\", 3, 15),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n",
    "        \"epochs\": trial.suggest_int(\"epochs\", 10, 50)\n",
    "    }\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run(run_name=\"MLP\"):\n",
    "        normalizer = preprocessing.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(train))\n",
    "        \n",
    "        mlp_model = tf.keras.Sequential([\n",
    "            normalizer,\n",
    "            layers.Dense(units=params[\"hidden_units\"]),\n",
    "            layers.Dense(units=params[\"hidden_units\"]),\n",
    "            layers.Dense(units=params[\"hidden_units\"]),\n",
    "            layers.Dense(units=1),\n",
    "        ])\n",
    "\n",
    "        mlp_model.summary()\n",
    "        \n",
    "        mlp_model.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=params[\"lr\"]),\n",
    "            loss='mean_squared_error'\n",
    "        )\n",
    "\n",
    "        history = mlp_model.fit(\n",
    "            train, train_labels,\n",
    "            validation_data=(test, test_labels),\n",
    "            epochs=params[\"epochs\"]\n",
    "        )\n",
    "        \n",
    "        predictions = mlp_model.predict(val)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
    "\n",
    "        # Print out model metrics\n",
    "        print(\"MLP model\")\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log mlflow attributes for mlflow UI\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.set_tags(\n",
    "            {\n",
    "                \"estimator_name\":\"MultiLayerPerceptron\",\n",
    "                \"estimator_class\":\"Keras\"\n",
    "            }\n",
    "        )\n",
    "        #mlflow.tensorflow.log_model(mlp_model, \"model\")\n",
    "        #modelpath = \"./mlflow/freight_value/model-mlp\"\n",
    "        #mlflow.tensorflow.save_model(mlp_model, modelpath)\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd5130",
   "metadata": {},
   "source": [
    "### Using optuna to optimize MLP's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d924f843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:26,967]\u001b[0m A new study created in memory with name: no-name-3da30d36-2ebb-49f4-a393-e89192289a9f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13)                24128     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 28,217\n",
      "Trainable params: 24,506\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/48\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 506.9647WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0036s vs `on_train_batch_end` time: 0.0098s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 15ms/step - loss: 540.9018 - val_loss: 514671968256.0000\n",
      "Epoch 2/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 540.2049 - val_loss: 513622147072.0000\n",
      "Epoch 3/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 539.8248 - val_loss: 512604209152.0000\n",
      "Epoch 4/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 539.4434 - val_loss: 511620481024.0000\n",
      "Epoch 5/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 539.0797 - val_loss: 510769758208.0000\n",
      "Epoch 6/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 538.7235 - val_loss: 509924278272.0000\n",
      "Epoch 7/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 538.3461 - val_loss: 509119463424.0000\n",
      "Epoch 8/48\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 537.9807 - val_loss: 508428615680.0000\n",
      "Epoch 9/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 537.6373 - val_loss: 507449049088.0000\n",
      "Epoch 10/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 537.2551 - val_loss: 506682408960.0000\n",
      "Epoch 11/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 536.9003 - val_loss: 505965281280.0000\n",
      "Epoch 12/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 536.5515 - val_loss: 505288130560.0000\n",
      "Epoch 13/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 536.1743 - val_loss: 504490688512.0000\n",
      "Epoch 14/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.8336 - val_loss: 503712940032.0000\n",
      "Epoch 15/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.4803 - val_loss: 503392305152.0000\n",
      "Epoch 16/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.1202 - val_loss: 502866444288.0000\n",
      "Epoch 17/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.7742 - val_loss: 502315745280.0000\n",
      "Epoch 18/48\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 534.4262 - val_loss: 501809414144.0000\n",
      "Epoch 19/48\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 534.0788 - val_loss: 501362819072.0000\n",
      "Epoch 20/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.7299 - val_loss: 501003321344.0000\n",
      "Epoch 21/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.3784 - val_loss: 500455211008.0000\n",
      "Epoch 22/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.0447 - val_loss: 500046004224.0000\n",
      "Epoch 23/48\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 532.6918 - val_loss: 499905167360.0000\n",
      "Epoch 24/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.3475 - val_loss: 499627425792.0000\n",
      "Epoch 25/48\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 531.9980 - val_loss: 499292766208.0000\n",
      "Epoch 26/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.6694 - val_loss: 498810290176.0000\n",
      "Epoch 27/48\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 531.3251 - val_loss: 498652741632.0000\n",
      "Epoch 28/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.9794 - val_loss: 498562203648.0000\n",
      "Epoch 29/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.6443 - val_loss: 498571247616.0000\n",
      "Epoch 30/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.3143 - val_loss: 498462457856.0000\n",
      "Epoch 31/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 529.9660 - val_loss: 498311200768.0000\n",
      "Epoch 32/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 529.6274 - val_loss: 498144509952.0000\n",
      "Epoch 33/48\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 529.2856 - val_loss: 498156044288.0000\n",
      "Epoch 34/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.9565 - val_loss: 498207948800.0000\n",
      "Epoch 35/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.6088 - val_loss: 498185502720.0000\n",
      "Epoch 36/48\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 528.2801 - val_loss: 498339971072.0000\n",
      "Epoch 37/48\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 527.9478 - val_loss: 498177507328.0000\n",
      "Epoch 38/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 527.6099 - val_loss: 498326798336.0000\n",
      "Epoch 39/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 527.2745 - val_loss: 498479693824.0000\n",
      "Epoch 40/48\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 526.9485 - val_loss: 498620334080.0000\n",
      "Epoch 41/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 526.6096 - val_loss: 498890702848.0000\n",
      "Epoch 42/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 526.2728 - val_loss: 499163168768.0000\n",
      "Epoch 43/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 525.9465 - val_loss: 499271335936.0000\n",
      "Epoch 44/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 525.6100 - val_loss: 499547275264.0000\n",
      "Epoch 45/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 525.2802 - val_loss: 499764199424.0000\n",
      "Epoch 46/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 524.9418 - val_loss: 500314603520.0000\n",
      "Epoch 47/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 524.6179 - val_loss: 500803829760.0000\n",
      "Epoch 48/48\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 524.2855 - val_loss: 501164048384.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpr47knx9v/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 762881.3161777382\n",
      "  MAE: 503161.3511584264\n",
      "  R2: -2765734226.5925603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:32,260]\u001b[0m Trial 0 finished with value: 762881.3161777382 and parameters: {'hidden_units': 13, 'lr': 1.2645740678991583e-05, 'epochs': 48}. Best is trial 0 with value: 762881.3161777382.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 14848     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 18,712\n",
      "Trainable params: 15,001\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/47\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 521.7957WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0038s vs `on_train_batch_end` time: 0.0089s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 13ms/step - loss: 536.6121 - val_loss: 73894846464.0000\n",
      "Epoch 2/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 536.3873 - val_loss: 73698738176.0000\n",
      "Epoch 3/47\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 536.2529 - val_loss: 73562521600.0000\n",
      "Epoch 4/47\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 536.1221 - val_loss: 73418080256.0000\n",
      "Epoch 5/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.9888 - val_loss: 73182846976.0000\n",
      "Epoch 6/47\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 535.8535 - val_loss: 73059901440.0000\n",
      "Epoch 7/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.7231 - val_loss: 72915386368.0000\n",
      "Epoch 8/47\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 535.5958 - val_loss: 72815091712.0000\n",
      "Epoch 9/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.4675 - val_loss: 72654905344.0000\n",
      "Epoch 10/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.3323 - val_loss: 72555569152.0000\n",
      "Epoch 11/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.2065 - val_loss: 72471625728.0000\n",
      "Epoch 12/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.0770 - val_loss: 72250236928.0000\n",
      "Epoch 13/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.9483 - val_loss: 72186544128.0000\n",
      "Epoch 14/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.8173 - val_loss: 72122916864.0000\n",
      "Epoch 15/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.6952 - val_loss: 71948976128.0000\n",
      "Epoch 16/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.5608 - val_loss: 71878778880.0000\n",
      "Epoch 17/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.4335 - val_loss: 71771627520.0000\n",
      "Epoch 18/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.3040 - val_loss: 71712612352.0000\n",
      "Epoch 19/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.1780 - val_loss: 71651172352.0000\n",
      "Epoch 20/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.0560 - val_loss: 71659175936.0000\n",
      "Epoch 21/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.9248 - val_loss: 71512244224.0000\n",
      "Epoch 22/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.7957 - val_loss: 71491149824.0000\n",
      "Epoch 23/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.6693 - val_loss: 71510327296.0000\n",
      "Epoch 24/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.5452 - val_loss: 71472111616.0000\n",
      "Epoch 25/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.4149 - val_loss: 71451607040.0000\n",
      "Epoch 26/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.2902 - val_loss: 71467155456.0000\n",
      "Epoch 27/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.1587 - val_loss: 71380238336.0000\n",
      "Epoch 28/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.0371 - val_loss: 71403126784.0000\n",
      "Epoch 29/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.9077 - val_loss: 71353810944.0000\n",
      "Epoch 30/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.7802 - val_loss: 71384064000.0000\n",
      "Epoch 31/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.6496 - val_loss: 71381811200.0000\n",
      "Epoch 32/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.5256 - val_loss: 71361863680.0000\n",
      "Epoch 33/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.3967 - val_loss: 71404199936.0000\n",
      "Epoch 34/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.2716 - val_loss: 71463575552.0000\n",
      "Epoch 35/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.1447 - val_loss: 71464009728.0000\n",
      "Epoch 36/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.0193 - val_loss: 71544217600.0000\n",
      "Epoch 37/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.8880 - val_loss: 71594999808.0000\n",
      "Epoch 38/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.7646 - val_loss: 71609376768.0000\n",
      "Epoch 39/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.6332 - val_loss: 71659503616.0000\n",
      "Epoch 40/47\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 531.5045 - val_loss: 71756521472.0000\n",
      "Epoch 41/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.3802 - val_loss: 71792615424.0000\n",
      "Epoch 42/47\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 531.2507 - val_loss: 71888076800.0000\n",
      "Epoch 43/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.1230 - val_loss: 71996841984.0000\n",
      "Epoch 44/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.9907 - val_loss: 72091402240.0000\n",
      "Epoch 45/47\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 530.8627 - val_loss: 72143642624.0000\n",
      "Epoch 46/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.7325 - val_loss: 72243609600.0000\n",
      "Epoch 47/47\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.6004 - val_loss: 72371118080.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpt0isree_/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 243418.12581651183\n",
      "  MAE: 163352.42093363608\n",
      "  R2: -281580330.3168814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:36,799]\u001b[0m Trial 1 finished with value: 243418.12581651183 and parameters: {'hidden_units': 8, 'lr': 1.3018700865964896e-05, 'epochs': 47}. Best is trial 1 with value: 243418.12581651183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 12992     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 16,823\n",
      "Trainable params: 13,112\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 466.4359WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0107s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 13ms/step - loss: 535.0430 - val_loss: 264669134848.0000\n",
      "Epoch 2/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.5141 - val_loss: 264512798720.0000\n",
      "Epoch 3/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.2158 - val_loss: 264326234112.0000\n",
      "Epoch 4/30\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 533.9344 - val_loss: 264007385088.0000\n",
      "Epoch 5/30\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 533.6367 - val_loss: 263900643328.0000\n",
      "Epoch 6/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.3525 - val_loss: 263837171712.0000\n",
      "Epoch 7/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.0627 - val_loss: 263738441728.0000\n",
      "Epoch 8/30\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 532.7764 - val_loss: 263813398528.0000\n",
      "Epoch 9/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.4871 - val_loss: 263822966784.0000\n",
      "Epoch 10/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.1912 - val_loss: 263794360320.0000\n",
      "Epoch 11/30\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 531.9072 - val_loss: 263962673152.0000\n",
      "Epoch 12/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.6146 - val_loss: 263957872640.0000\n",
      "Epoch 13/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.3215 - val_loss: 264174895104.0000\n",
      "Epoch 14/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.0392 - val_loss: 264201158656.0000\n",
      "Epoch 15/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.7425 - val_loss: 264271937536.0000\n",
      "Epoch 16/30\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 530.4585 - val_loss: 264716484608.0000\n",
      "Epoch 17/30\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 530.1602 - val_loss: 264829386752.0000\n",
      "Epoch 18/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 529.8692 - val_loss: 264909144064.0000\n",
      "Epoch 19/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 529.5799 - val_loss: 265516220416.0000\n",
      "Epoch 20/30\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 529.2864 - val_loss: 265656680448.0000\n",
      "Epoch 21/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.9905 - val_loss: 265929490432.0000\n",
      "Epoch 22/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.6933 - val_loss: 266314989568.0000\n",
      "Epoch 23/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.4008 - val_loss: 266673995776.0000\n",
      "Epoch 24/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.1036 - val_loss: 267226890240.0000\n",
      "Epoch 25/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 527.7980 - val_loss: 267445616640.0000\n",
      "Epoch 26/30\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 527.5059 - val_loss: 267974606848.0000\n",
      "Epoch 27/30\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 527.2130 - val_loss: 268911083520.0000\n",
      "Epoch 28/30\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 526.9022 - val_loss: 269232750592.0000\n",
      "Epoch 29/30\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 526.6013 - val_loss: 269966524416.0000\n",
      "Epoch 30/30\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 526.3002 - val_loss: 270567407616.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0_w6_btx/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 532486.7892691911\n",
      "  MAE: 375876.40234114235\n",
      "  R2: -1347454663.9319139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:40,388]\u001b[0m Trial 2 finished with value: 532486.7892691911 and parameters: {'hidden_units': 7, 'lr': 1.921014348470924e-05, 'epochs': 30}. Best is trial 1 with value: 243418.12581651183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                20416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24,403\n",
      "Trainable params: 20,692\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/49\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 435.3662WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0091s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 14ms/step - loss: 537.5350 - val_loss: 121847554048.0000\n",
      "Epoch 2/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.6344 - val_loss: 120101388288.0000\n",
      "Epoch 3/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.5569 - val_loss: 119186227200.0000\n",
      "Epoch 4/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.5084 - val_loss: 118407495680.0000\n",
      "Epoch 5/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.5168 - val_loss: 118057140224.0000\n",
      "Epoch 6/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.4973 - val_loss: 117820719104.0000\n",
      "Epoch 7/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.4787 - val_loss: 118347677696.0000\n",
      "Epoch 8/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 529.5020 - val_loss: 118447603712.0000\n",
      "Epoch 9/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.4670 - val_loss: 118973366272.0000\n",
      "Epoch 10/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 527.4518 - val_loss: 119940980736.0000\n",
      "Epoch 11/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 526.4489 - val_loss: 121243435008.0000\n",
      "Epoch 12/49\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 525.3759 - val_loss: 122469507072.0000\n",
      "Epoch 13/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 524.3587 - val_loss: 124641320960.0000\n",
      "Epoch 14/49\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 523.2647 - val_loss: 126049140736.0000\n",
      "Epoch 15/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 522.1827 - val_loss: 128772743168.0000\n",
      "Epoch 16/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 521.0522 - val_loss: 131011133440.0000\n",
      "Epoch 17/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 519.8885 - val_loss: 133687558144.0000\n",
      "Epoch 18/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 518.7241 - val_loss: 137561505792.0000\n",
      "Epoch 19/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 517.5154 - val_loss: 140759597056.0000\n",
      "Epoch 20/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 516.2367 - val_loss: 144403955712.0000\n",
      "Epoch 21/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 515.0096 - val_loss: 148947009536.0000\n",
      "Epoch 22/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 513.6273 - val_loss: 152814731264.0000\n",
      "Epoch 23/49\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 512.2963 - val_loss: 158197334016.0000\n",
      "Epoch 24/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 510.8258 - val_loss: 163186294784.0000\n",
      "Epoch 25/49\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 509.3683 - val_loss: 169200140288.0000\n",
      "Epoch 26/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 507.7884 - val_loss: 174982217728.0000\n",
      "Epoch 27/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 506.2887 - val_loss: 181656551424.0000\n",
      "Epoch 28/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 504.6443 - val_loss: 188339257344.0000\n",
      "Epoch 29/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 502.9536 - val_loss: 195980263424.0000\n",
      "Epoch 30/49\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 501.1576 - val_loss: 203033804800.0000\n",
      "Epoch 31/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 499.4045 - val_loss: 212137132032.0000\n",
      "Epoch 32/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 497.5132 - val_loss: 220890021888.0000\n",
      "Epoch 33/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 495.5389 - val_loss: 230902710272.0000\n",
      "Epoch 34/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 493.5319 - val_loss: 241559535616.0000\n",
      "Epoch 35/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 491.5182 - val_loss: 252547809280.0000\n",
      "Epoch 36/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 489.3481 - val_loss: 264145977344.0000\n",
      "Epoch 37/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 487.1587 - val_loss: 277242281984.0000\n",
      "Epoch 38/49\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 484.7852 - val_loss: 290000076800.0000\n",
      "Epoch 39/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 482.5417 - val_loss: 304154935296.0000\n",
      "Epoch 40/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 480.0251 - val_loss: 318516035584.0000\n",
      "Epoch 41/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 477.5903 - val_loss: 333361250304.0000\n",
      "Epoch 42/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 475.0588 - val_loss: 350165991424.0000\n",
      "Epoch 43/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 472.3941 - val_loss: 367106064384.0000\n",
      "Epoch 44/49\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 469.6102 - val_loss: 383935348736.0000\n",
      "Epoch 45/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 466.9463 - val_loss: 404088651776.0000\n",
      "Epoch 46/49\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 464.0592 - val_loss: 424676261888.0000\n",
      "Epoch 47/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 461.0508 - val_loss: 445700079616.0000\n",
      "Epoch 48/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 458.0951 - val_loss: 467411140608.0000\n",
      "Epoch 49/49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 454.9777 - val_loss: 489166209024.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmptkmizuhi/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 731815.3302318369\n",
      "  MAE: 500255.15342425776\n",
      "  R2: -2545068599.564637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:45,176]\u001b[0m Trial 3 finished with value: 731815.3302318369 and parameters: {'hidden_units': 11, 'lr': 6.693371085081771e-05, 'epochs': 49}. Best is trial 1 with value: 243418.12581651183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 5568      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 9,307\n",
      "Trainable params: 5,596\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/28\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 520.1292WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0097s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 13ms/step - loss: 539.1427 - val_loss: 337227546624.0000\n",
      "Epoch 2/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 536.9760 - val_loss: 334464385024.0000\n",
      "Epoch 3/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.7488 - val_loss: 331858149376.0000\n",
      "Epoch 4/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.5659 - val_loss: 329920970752.0000\n",
      "Epoch 5/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.4235 - val_loss: 327577534464.0000\n",
      "Epoch 6/28\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 532.2420 - val_loss: 325948899328.0000\n",
      "Epoch 7/28\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 531.1252 - val_loss: 325144870912.0000\n",
      "Epoch 8/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 529.9566 - val_loss: 323307929600.0000\n",
      "Epoch 9/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.8066 - val_loss: 322616131584.0000\n",
      "Epoch 10/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 527.6665 - val_loss: 321529249792.0000\n",
      "Epoch 11/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 526.5676 - val_loss: 321769078784.0000\n",
      "Epoch 12/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 525.3945 - val_loss: 320989331456.0000\n",
      "Epoch 13/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 524.2903 - val_loss: 322097709056.0000\n",
      "Epoch 14/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 523.1348 - val_loss: 321777500160.0000\n",
      "Epoch 15/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 521.9749 - val_loss: 322434596864.0000\n",
      "Epoch 16/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 520.8281 - val_loss: 323887529984.0000\n",
      "Epoch 17/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 519.6617 - val_loss: 324742676480.0000\n",
      "Epoch 18/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 518.4930 - val_loss: 325828542464.0000\n",
      "Epoch 19/28\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 517.2748 - val_loss: 327480836096.0000\n",
      "Epoch 20/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 516.1041 - val_loss: 329724264448.0000\n",
      "Epoch 21/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 514.9360 - val_loss: 332217516032.0000\n",
      "Epoch 22/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 513.6950 - val_loss: 335098019840.0000\n",
      "Epoch 23/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 512.4114 - val_loss: 337447649280.0000\n",
      "Epoch 24/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 511.1658 - val_loss: 339734102016.0000\n",
      "Epoch 25/28\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 509.9065 - val_loss: 343565565952.0000\n",
      "Epoch 26/28\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 508.5670 - val_loss: 346857832448.0000\n",
      "Epoch 27/28\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 507.2672 - val_loss: 351232819200.0000\n",
      "Epoch 28/28\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 506.0150 - val_loss: 354944286720.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpggevnl92/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 656167.3836285687\n",
      "  MAE: 448670.69696169806\n",
      "  R2: -2046094861.5775526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:48,813]\u001b[0m Trial 4 finished with value: 656167.3836285687 and parameters: {'hidden_units': 3, 'lr': 9.128537121695166e-05, 'epochs': 28}. Best is trial 1 with value: 243418.12581651183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 11136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 14,938\n",
      "Trainable params: 11,227\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 678.0377WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0095s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 11ms/step - loss: 536.2347 - val_loss: 159690653696.0000\n",
      "Epoch 2/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.9500 - val_loss: 159480578048.0000\n",
      "Epoch 3/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.7905 - val_loss: 159296864256.0000\n",
      "Epoch 4/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.6307 - val_loss: 159113084928.0000\n",
      "Epoch 5/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.4749 - val_loss: 158850891776.0000\n",
      "Epoch 6/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.3203 - val_loss: 158777016320.0000\n",
      "Epoch 7/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.1573 - val_loss: 158699290624.0000\n",
      "Epoch 8/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.0038 - val_loss: 158571331584.0000\n",
      "Epoch 9/35\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 534.8469 - val_loss: 158420434944.0000\n",
      "Epoch 10/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.6889 - val_loss: 158420353024.0000\n",
      "Epoch 11/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.5328 - val_loss: 158292197376.0000\n",
      "Epoch 12/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.3762 - val_loss: 158239277056.0000\n",
      "Epoch 13/35\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 534.2163 - val_loss: 158154522624.0000\n",
      "Epoch 14/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.0633 - val_loss: 158125162496.0000\n",
      "Epoch 15/35\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 533.9141 - val_loss: 158019682304.0000\n",
      "Epoch 16/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.7434 - val_loss: 157999628288.0000\n",
      "Epoch 17/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.5930 - val_loss: 158074667008.0000\n",
      "Epoch 18/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.4382 - val_loss: 158036328448.0000\n",
      "Epoch 19/35\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 533.2773 - val_loss: 157942153216.0000\n",
      "Epoch 20/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.1207 - val_loss: 158015668224.0000\n",
      "Epoch 21/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.9688 - val_loss: 158105812992.0000\n",
      "Epoch 22/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.8083 - val_loss: 158118903808.0000\n",
      "Epoch 23/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.6533 - val_loss: 158158274560.0000\n",
      "Epoch 24/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.4950 - val_loss: 158174855168.0000\n",
      "Epoch 25/35\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 532.3358 - val_loss: 158257709056.0000\n",
      "Epoch 26/35\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 532.1778 - val_loss: 158311743488.0000\n",
      "Epoch 27/35\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 532.0212 - val_loss: 158471077888.0000\n",
      "Epoch 28/35\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 531.8683 - val_loss: 158582620160.0000\n",
      "Epoch 29/35\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 531.7064 - val_loss: 158721572864.0000\n",
      "Epoch 30/35\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 531.5444 - val_loss: 158827020288.0000\n",
      "Epoch 31/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.3861 - val_loss: 158964187136.0000\n",
      "Epoch 32/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.2316 - val_loss: 159059116032.0000\n",
      "Epoch 33/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.0652 - val_loss: 159221710848.0000\n",
      "Epoch 34/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.9130 - val_loss: 159370919936.0000\n",
      "Epoch 35/35\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.7465 - val_loss: 159529893888.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpcciyp006/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 409633.76713693945\n",
      "  MAE: 283320.8970355976\n",
      "  R2: -797421581.6441741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:52,789]\u001b[0m Trial 5 finished with value: 409633.76713693945 and parameters: {'hidden_units': 6, 'lr': 1.439895271967439e-05, 'epochs': 35}. Best is trial 1 with value: 243418.12581651183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                20416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24,403\n",
      "Trainable params: 20,692\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/24\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 435.5112WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0091s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 13ms/step - loss: 535.9781 - val_loss: 99152396288.0000\n",
      "Epoch 2/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.0467 - val_loss: 98176147456.0000\n",
      "Epoch 3/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.2111 - val_loss: 98316992512.0000\n",
      "Epoch 4/24\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 529.4918 - val_loss: 98785959936.0000\n",
      "Epoch 5/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 527.6738 - val_loss: 100057923584.0000\n",
      "Epoch 6/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 525.8582 - val_loss: 102481051648.0000\n",
      "Epoch 7/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 523.8713 - val_loss: 105179709440.0000\n",
      "Epoch 8/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 521.8210 - val_loss: 109083394048.0000\n",
      "Epoch 9/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 519.6332 - val_loss: 114738429952.0000\n",
      "Epoch 10/24\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 517.2278 - val_loss: 120476450816.0000\n",
      "Epoch 11/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 514.8759 - val_loss: 127006449664.0000\n",
      "Epoch 12/24\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 512.0271 - val_loss: 135007600640.0000\n",
      "Epoch 13/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 509.2513 - val_loss: 146271961088.0000\n",
      "Epoch 14/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 506.0617 - val_loss: 157783982080.0000\n",
      "Epoch 15/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 502.5179 - val_loss: 170631495680.0000\n",
      "Epoch 16/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 498.9246 - val_loss: 186094927872.0000\n",
      "Epoch 17/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 495.0718 - val_loss: 206105083904.0000\n",
      "Epoch 18/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 490.6609 - val_loss: 225912766464.0000\n",
      "Epoch 19/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 486.0243 - val_loss: 248343707648.0000\n",
      "Epoch 20/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 481.1432 - val_loss: 276475117568.0000\n",
      "Epoch 21/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 475.9354 - val_loss: 306555617280.0000\n",
      "Epoch 22/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 470.1431 - val_loss: 339248513024.0000\n",
      "Epoch 23/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 464.4936 - val_loss: 379228553216.0000\n",
      "Epoch 24/24\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 458.2197 - val_loss: 420912136192.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpcg15e0my/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 568249.6463792608\n",
      "  MAE: 397029.6640460529\n",
      "  R2: -1534528062.8186579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:56,060]\u001b[0m Trial 6 finished with value: 568249.6463792608 and parameters: {'hidden_units': 11, 'lr': 0.00012740202766212662, 'epochs': 24}. Best is trial 1 with value: 243418.12581651183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 12992     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 16,823\n",
      "Trainable params: 13,112\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 516.6502WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0113s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 14ms/step - loss: 539.3472 - val_loss: 145103241216.0000\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 535.1060 - val_loss: 142667841536.0000\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.8400 - val_loss: 140852690944.0000\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.6547 - val_loss: 140748767232.0000\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.5325 - val_loss: 141491978240.0000\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 526.2686 - val_loss: 142651899904.0000\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 524.0572 - val_loss: 145231396864.0000\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 521.7932 - val_loss: 149231140864.0000\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 519.4133 - val_loss: 153217384448.0000\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 517.0269 - val_loss: 159390760960.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpve_xizud/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 414396.67002250714\n",
      "  MAE: 264798.5847146938\n",
      "  R2: -816072982.9702724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:34:58,486]\u001b[0m Trial 7 finished with value: 414396.67002250714 and parameters: {'hidden_units': 7, 'lr': 0.0001882715981204829, 'epochs': 10}. Best is trial 1 with value: 243418.12581651183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                18560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 22,502\n",
      "Trainable params: 18,791\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/45\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 765.6810WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0042s vs `on_train_batch_end` time: 0.0099s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 14ms/step - loss: 535.5904 - val_loss: 145451270144.0000\n",
      "Epoch 2/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 534.2736 - val_loss: 144790306816.0000\n",
      "Epoch 3/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 533.5569 - val_loss: 144497606656.0000\n",
      "Epoch 4/45\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 532.8388 - val_loss: 144219127808.0000\n",
      "Epoch 5/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.1469 - val_loss: 144080830464.0000\n",
      "Epoch 6/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 531.4766 - val_loss: 144353427456.0000\n",
      "Epoch 7/45\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 530.7726 - val_loss: 144537288704.0000\n",
      "Epoch 8/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 530.0704 - val_loss: 144616849408.0000\n",
      "Epoch 9/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 529.3869 - val_loss: 145471504384.0000\n",
      "Epoch 10/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.7108 - val_loss: 146388221952.0000\n",
      "Epoch 11/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 528.0024 - val_loss: 147549945856.0000\n",
      "Epoch 12/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 527.2935 - val_loss: 148195016704.0000\n",
      "Epoch 13/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 526.5967 - val_loss: 149186002944.0000\n",
      "Epoch 14/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 525.8812 - val_loss: 151013867520.0000\n",
      "Epoch 15/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 525.1424 - val_loss: 152834162688.0000\n",
      "Epoch 16/45\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 524.4086 - val_loss: 154605256704.0000\n",
      "Epoch 17/45\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 523.6348 - val_loss: 156363784192.0000\n",
      "Epoch 18/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 522.8951 - val_loss: 158395777024.0000\n",
      "Epoch 19/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 522.1470 - val_loss: 161008369664.0000\n",
      "Epoch 20/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 521.3196 - val_loss: 163418800128.0000\n",
      "Epoch 21/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 520.5280 - val_loss: 166028427264.0000\n",
      "Epoch 22/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 519.7207 - val_loss: 169037217792.0000\n",
      "Epoch 23/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 518.9327 - val_loss: 172518604800.0000\n",
      "Epoch 24/45\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 518.0352 - val_loss: 175669067776.0000\n",
      "Epoch 25/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 517.1663 - val_loss: 179309281280.0000\n",
      "Epoch 26/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 516.2672 - val_loss: 182476324864.0000\n",
      "Epoch 27/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 515.3656 - val_loss: 186473005056.0000\n",
      "Epoch 28/45\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 514.4550 - val_loss: 190964629504.0000\n",
      "Epoch 29/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 513.4502 - val_loss: 195163045888.0000\n",
      "Epoch 30/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 512.5239 - val_loss: 200251490304.0000\n",
      "Epoch 31/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 511.4771 - val_loss: 205150011392.0000\n",
      "Epoch 32/45\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 510.4614 - val_loss: 210616008704.0000\n",
      "Epoch 33/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 509.3984 - val_loss: 215829659648.0000\n",
      "Epoch 34/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 508.3124 - val_loss: 221442048000.0000\n",
      "Epoch 35/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 507.2262 - val_loss: 227633315840.0000\n",
      "Epoch 36/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 506.0668 - val_loss: 234531913728.0000\n",
      "Epoch 37/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 504.8589 - val_loss: 241046503424.0000\n",
      "Epoch 38/45\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 503.6603 - val_loss: 248384667648.0000\n",
      "Epoch 39/45\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 502.4044 - val_loss: 255792644096.0000\n",
      "Epoch 40/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 501.1156 - val_loss: 263404290048.0000\n",
      "Epoch 41/45\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 499.7921 - val_loss: 270854619136.0000\n",
      "Epoch 42/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 498.5091 - val_loss: 279421255680.0000\n",
      "Epoch 43/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 497.1363 - val_loss: 288980598784.0000\n",
      "Epoch 44/45\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 495.6893 - val_loss: 298297163776.0000\n",
      "Epoch 45/45\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 494.2356 - val_loss: 307851755520.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpvxnn44g4/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 587205.4544958103\n",
      "  MAE: 397632.45630970993\n",
      "  R2: -1638613954.0129895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:02,935]\u001b[0m Trial 8 finished with value: 587205.4544958103 and parameters: {'hidden_units': 10, 'lr': 4.871522981572731e-05, 'epochs': 45}. Best is trial 1 with value: 243418.12581651183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 1855)              3711      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 9280      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 13,057\n",
      "Trainable params: 9,346\n",
      "Non-trainable params: 3,711\n",
      "_________________________________________________________________\n",
      "Epoch 1/22\n",
      " 3/19 [===>..........................] - ETA: 0s - loss: 671.9225WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0092s). Check your callbacks.\n",
      "19/19 [==============================] - 1s 13ms/step - loss: 539.4087 - val_loss: 76868624384.0000\n",
      "Epoch 2/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 532.3596 - val_loss: 75528134656.0000\n",
      "Epoch 3/22\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 528.7969 - val_loss: 77341851648.0000\n",
      "Epoch 4/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 525.1713 - val_loss: 83717103616.0000\n",
      "Epoch 5/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 521.2643 - val_loss: 92667019264.0000\n",
      "Epoch 6/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 517.0204 - val_loss: 106499219456.0000\n",
      "Epoch 7/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 511.9155 - val_loss: 121859743744.0000\n",
      "Epoch 8/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 506.4388 - val_loss: 142613004288.0000\n",
      "Epoch 9/22\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 499.6574 - val_loss: 166544326656.0000\n",
      "Epoch 10/22\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 492.5619 - val_loss: 199785463808.0000\n",
      "Epoch 11/22\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 484.1256 - val_loss: 235788959744.0000\n",
      "Epoch 12/22\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 474.5587 - val_loss: 277656436736.0000\n",
      "Epoch 13/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 464.5851 - val_loss: 333261144064.0000\n",
      "Epoch 14/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 452.7117 - val_loss: 392714027008.0000\n",
      "Epoch 15/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 440.6462 - val_loss: 464260890624.0000\n",
      "Epoch 16/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 427.3246 - val_loss: 545097908224.0000\n",
      "Epoch 17/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 413.2552 - val_loss: 632279597056.0000\n",
      "Epoch 18/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 398.8561 - val_loss: 737100496896.0000\n",
      "Epoch 19/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 383.6849 - val_loss: 846931034112.0000\n",
      "Epoch 20/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 368.4294 - val_loss: 979024150528.0000\n",
      "Epoch 21/22\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 351.9574 - val_loss: 1115625357312.0000\n",
      "Epoch 22/22\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 337.3928 - val_loss: 1281153171456.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3rke2tii/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 1198343.9028469082\n",
      "  MAE: 794079.5947992839\n",
      "  R2: -6824320705.054222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:06,035]\u001b[0m Trial 9 finished with value: 1198343.9028469082 and parameters: {'hidden_units': 5, 'lr': 0.0004429587786509501, 'epochs': 22}. Best is trial 1 with value: 243418.12581651183.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(mlp, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b307794",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fd6df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(trial):\n",
    "    train, test, val = get_x_data()\n",
    "    train_labels, val_labels, test_labels = get_y_data()\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 5),\n",
    "    }\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "        rf = RandomForestRegressor(\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            min_samples_split=params[\"min_samples_split\"],\n",
    "            random_state=0\n",
    "        )\n",
    "        rf.fit(train, train_labels)\n",
    "        \n",
    "        predictions = rf.predict(val)\n",
    "        \n",
    "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
    "        \n",
    "        print(\"Random Forest model\")\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "        \n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_params(trial.params)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fcbca4",
   "metadata": {},
   "source": [
    "### Using optuna to optimize Random Forest's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0616b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:06,054]\u001b[0m A new study created in memory with name: no-name-a12e8918-f381-4cd1-af42-eded737eec6d\u001b[0m\n",
      "\u001b[32m[I 2021-08-15 23:35:07,671]\u001b[0m Trial 0 finished with value: 15.028769774006358 and parameters: {'n_estimators': 134, 'max_depth': 4, 'min_samples_split': 4}. Best is trial 0 with value: 15.028769774006358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 15.028769774006358\n",
      "  MAE: 9.24944312378477\n",
      "  R2: -0.07335491700964591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:09,357]\u001b[0m Trial 1 finished with value: 15.616548157282168 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 0 with value: 15.028769774006358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 15.616548157282168\n",
      "  MAE: 9.487153705419797\n",
      "  R2: -0.15895500840076604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:10,631]\u001b[0m Trial 2 finished with value: 15.302392666498529 and parameters: {'n_estimators': 61, 'max_depth': 7, 'min_samples_split': 2}. Best is trial 0 with value: 15.028769774006358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 15.302392666498529\n",
      "  MAE: 9.34541157704586\n",
      "  R2: -0.11279501375190004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:12,477]\u001b[0m Trial 3 finished with value: 15.679531718904316 and parameters: {'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 2}. Best is trial 0 with value: 15.028769774006358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 15.679531718904316\n",
      "  MAE: 9.502150244145167\n",
      "  R2: -0.16832229146841438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:14,356]\u001b[0m Trial 4 finished with value: 15.244090230273448 and parameters: {'n_estimators': 132, 'max_depth': 6, 'min_samples_split': 3}. Best is trial 0 with value: 15.028769774006358.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 15.244090230273448\n",
      "  MAE: 9.315441265976306\n",
      "  R2: -0.10433162280311103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:15,849]\u001b[0m Trial 5 finished with value: 14.912817434180642 and parameters: {'n_estimators': 141, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 5 with value: 14.912817434180642.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 14.912817434180642\n",
      "  MAE: 9.20049717834161\n",
      "  R2: -0.056856175344866866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:17,307]\u001b[0m Trial 6 finished with value: 15.583816889660739 and parameters: {'n_estimators': 61, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 5 with value: 14.912817434180642.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 15.583816889660739\n",
      "  MAE: 9.492343794300764\n",
      "  R2: -0.154101911225468\n",
      "Random Forest model\n",
      "  RMSE: 14.869604418574337\n",
      "  MAE: 9.190870189117215\n",
      "  R2: -0.050740124708194445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:18,658]\u001b[0m Trial 7 finished with value: 14.869604418574337 and parameters: {'n_estimators': 89, 'max_depth': 3, 'min_samples_split': 2}. Best is trial 7 with value: 14.869604418574337.\u001b[0m\n",
      "\u001b[32m[I 2021-08-15 23:35:20,508]\u001b[0m Trial 8 finished with value: 15.641466298625234 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 4}. Best is trial 7 with value: 14.869604418574337.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 15.641466298625234\n",
      "  MAE: 9.476235779929917\n",
      "  R2: -0.16265647231419078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:35:21,669]\u001b[0m Trial 9 finished with value: 14.989840814110146 and parameters: {'n_estimators': 74, 'max_depth': 4, 'min_samples_split': 2}. Best is trial 7 with value: 14.869604418574337.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 14.989840814110146\n",
      "  MAE: 9.24752355687862\n",
      "  R2: -0.06780150526396178\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(random_forest, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872d6a3",
   "metadata": {},
   "source": [
    "## Gradient Boosting with LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6c47a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(trial):\n",
    "    train, test, val = get_x_data()\n",
    "    train_labels, val_labels, test_labels = get_y_data()\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 25, 35),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    }\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"Gradient Boosting\"):\n",
    "#         model = LGBMRegressor(\n",
    "#             max_depth=params[\"max_depth\"],\n",
    "#             n_estimators=params[\"n_estimators\"],\n",
    "#             num_leaves=params[\"num_leaves\"],\n",
    "#         )\n",
    "        model = XGBRegressor(\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "        )\n",
    "        model.fit(train, train_labels)\n",
    "        \n",
    "        predictions = model.predict(test)\n",
    "        print('Prediction: %.3f' % predictions[0])\n",
    "        \n",
    "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
    "\n",
    "        print(\"LGBM model\")\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log mlflow attributes for mlflow UI\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.set_tags(\n",
    "            {\n",
    "                \"estimator_class\":\"LightGBM\",\n",
    "                \"estimator_name\":\"Gradient Boosting\"\n",
    "            }\n",
    "        )\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19013283",
   "metadata": {},
   "source": [
    "### Using optuna to optimize Gradient Boosting's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "302c2818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:36:06,187]\u001b[0m A new study created in memory with name: no-name-b6c9b334-f886-4dd1-b657-7d00750392df\u001b[0m\n",
      "\u001b[32m[I 2021-08-15 23:36:09,574]\u001b[0m Trial 0 finished with value: 16.125656800791422 and parameters: {'n_estimators': 110, 'num_leaves': 32, 'max_depth': 5}. Best is trial 0 with value: 16.125656800791422.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 26.947\n",
      "LGBM model\n",
      "  RMSE: 16.125656800791422\n",
      "  MAE: 10.054394902801514\n",
      "  R2: -0.23575197196477937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:36:12,045]\u001b[0m Trial 1 finished with value: 15.68434129076245 and parameters: {'n_estimators': 83, 'num_leaves': 29, 'max_depth': 4}. Best is trial 1 with value: 15.68434129076245.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 20.498\n",
      "LGBM model\n",
      "  RMSE: 15.68434129076245\n",
      "  MAE: 9.609959377098084\n",
      "  R2: -0.16903914856935187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:36:13,564]\u001b[0m Trial 2 finished with value: 15.294295479565868 and parameters: {'n_estimators': 57, 'num_leaves': 35, 'max_depth': 3}. Best is trial 2 with value: 15.294295479565868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 18.420\n",
      "LGBM model\n",
      "  RMSE: 15.294295479565868\n",
      "  MAE: 9.32500130119324\n",
      "  R2: -0.11161766514939697\n",
      "Prediction: 27.618\n",
      "LGBM model\n",
      "  RMSE: 16.950889388448477\n",
      "  MAE: 10.797867583084107\n",
      "  R2: -0.365467811661512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:36:20,882]\u001b[0m Trial 3 finished with value: 16.950889388448477 and parameters: {'n_estimators': 119, 'num_leaves': 25, 'max_depth': 8}. Best is trial 2 with value: 15.294295479565868.\u001b[0m\n",
      "\u001b[32m[I 2021-08-15 23:36:26,684]\u001b[0m Trial 4 finished with value: 16.85151561892738 and parameters: {'n_estimators': 143, 'num_leaves': 32, 'max_depth': 7}. Best is trial 2 with value: 15.294295479565868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 36.101\n",
      "LGBM model\n",
      "  RMSE: 16.85151561892738\n",
      "  MAE: 10.72845723590851\n",
      "  R2: -0.3495047624625385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:36:28,683]\u001b[0m Trial 5 finished with value: 15.73250800796823 and parameters: {'n_estimators': 60, 'num_leaves': 25, 'max_depth': 5}. Best is trial 2 with value: 15.294295479565868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 24.977\n",
      "LGBM model\n",
      "  RMSE: 15.73250800796823\n",
      "  MAE: 9.729811142158509\n",
      "  R2: -0.17623042799174415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:36:31,599]\u001b[0m Trial 6 finished with value: 16.071414224059467 and parameters: {'n_estimators': 95, 'num_leaves': 27, 'max_depth': 5}. Best is trial 2 with value: 15.294295479565868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 25.012\n",
      "LGBM model\n",
      "  RMSE: 16.071414224059467\n",
      "  MAE: 9.953289933586122\n",
      "  R2: -0.22745244835557177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:36:34,660]\u001b[0m Trial 7 finished with value: 16.096463090082608 and parameters: {'n_estimators': 100, 'num_leaves': 35, 'max_depth': 5}. Best is trial 2 with value: 15.294295479565868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 26.178\n",
      "LGBM model\n",
      "  RMSE: 16.096463090082608\n",
      "  MAE: 10.0064317401886\n",
      "  R2: -0.23128163874871466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:36:43,535]\u001b[0m Trial 8 finished with value: 16.878638207733626 and parameters: {'n_estimators': 140, 'num_leaves': 34, 'max_depth': 10}. Best is trial 2 with value: 15.294295479565868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 30.312\n",
      "LGBM model\n",
      "  RMSE: 16.878638207733626\n",
      "  MAE: 10.67378908352852\n",
      "  R2: -0.3538523261100506\n",
      "Prediction: 30.309\n",
      "LGBM model\n",
      "  RMSE: 16.875874308867214\n",
      "  MAE: 10.67277538971901\n",
      "  R2: -0.35340897226929746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 23:36:52,312]\u001b[0m Trial 9 finished with value: 16.875874308867214 and parameters: {'n_estimators': 139, 'num_leaves': 35, 'max_depth': 10}. Best is trial 2 with value: 15.294295479565868.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(gradient_boosting, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3847097",
   "metadata": {},
   "source": [
    "## Selecting best model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
