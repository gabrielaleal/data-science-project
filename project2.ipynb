{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b4e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "import gc\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1747e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed_precision.set_global_policy('mixed_float16')\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c781e0",
   "metadata": {},
   "source": [
    "## Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09fbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('project1_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a7c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll get a subset of our dataset in order to make experiments faster\n",
    "#df = df[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0bc65",
   "metadata": {},
   "source": [
    "#### Converting cols to their appropriate types again because we lost it on the csv export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fbdbe54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"product_category_name\"] = df[\"product_category_name\"].astype('category')\n",
    "df[\"order_status\"] = df[\"order_status\"].astype('category')\n",
    "df[\"review_score\"] = df[\"review_score\"].astype('category')\n",
    "df[\"payment_type\"] = df[\"payment_type\"].astype('category')\n",
    "df[\"customer_zip_code_prefix\"] = df[\"customer_zip_code_prefix\"].astype('category')\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype('category')\n",
    "df[\"customer_state\"] = df[\"customer_state\"].astype('category')\n",
    "df[\"seller_zip_code_prefix\"] = df[\"seller_zip_code_prefix\"].astype('category')\n",
    "df[\"seller_city\"] = df[\"seller_city\"].astype('category')\n",
    "df[\"seller_state\"] = df[\"seller_state\"].astype('category')\n",
    "\n",
    "df[\"product_name_lenght\"] = df[\"product_name_lenght\"].astype('int64')\n",
    "df[\"product_description_lenght\"] = df[\"product_description_lenght\"].astype('int64')\n",
    "df[\"product_photos_qty\"] = df[\"product_photos_qty\"].astype('int64')\n",
    "df[\"payment_installments\"] = df[\"payment_installments\"].astype('int64')\n",
    "df[\"payment_sequential\"] = df[\"payment_sequential\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076bef45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                           object\n",
       "order_item_id                       int64\n",
       "product_id                         object\n",
       "seller_id                          object\n",
       "shipping_limit_date                object\n",
       "price                             float64\n",
       "freight_value                     float64\n",
       "product_category_name            category\n",
       "product_name_lenght                 int64\n",
       "product_description_lenght          int64\n",
       "product_photos_qty                  int64\n",
       "product_weight_g                  float64\n",
       "product_length_cm                 float64\n",
       "product_height_cm                 float64\n",
       "product_width_cm                  float64\n",
       "customer_id                        object\n",
       "order_status                     category\n",
       "order_purchase_timestamp           object\n",
       "order_approved_at                  object\n",
       "order_delivered_carrier_date       object\n",
       "order_delivered_customer_date      object\n",
       "order_estimated_delivery_date      object\n",
       "review_id                          object\n",
       "review_score                     category\n",
       "review_creation_date               object\n",
       "review_answer_timestamp            object\n",
       "payment_sequential                  int64\n",
       "payment_type                     category\n",
       "payment_installments                int64\n",
       "payment_value                     float64\n",
       "customer_unique_id                 object\n",
       "customer_zip_code_prefix         category\n",
       "customer_city                    category\n",
       "customer_state                   category\n",
       "seller_zip_code_prefix           category\n",
       "seller_city                      category\n",
       "seller_state                     category\n",
       "payment_value_norm                float64\n",
       "payment_value_dist                 object\n",
       "volume                            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d661d06",
   "metadata": {},
   "source": [
    "#### Droping unnecessary columns\n",
    "We only want to work with numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd0c918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "839d9829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_item_id', 'price', 'freight_value', 'product_category_name',\n",
       "       'product_name_lenght', 'product_description_lenght',\n",
       "       'product_photos_qty', 'product_weight_g', 'product_length_cm',\n",
       "       'product_height_cm', 'product_width_cm', 'order_status', 'review_score',\n",
       "       'payment_sequential', 'payment_type', 'payment_installments',\n",
       "       'payment_value', 'customer_zip_code_prefix', 'customer_city',\n",
       "       'customer_state', 'seller_zip_code_prefix', 'seller_city',\n",
       "       'seller_state', 'payment_value_norm', 'volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095deda2",
   "metadata": {},
   "source": [
    "We'll also drop the `payment_value` column because our model would simply infer our target value from it by subtracting it from the `price` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee80e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['payment_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ade1c",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "Here we'll one-hot encode all of our categorical columns, and then drop the original ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888fbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df = df.select_dtypes(exclude=['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87163958",
   "metadata": {},
   "source": [
    "Even though we generated over 22000 columns this way, we believe that our model will be powerful enough to filter out any unecessary data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf542d7f",
   "metadata": {},
   "source": [
    "## Picking column for prediction\n",
    "\n",
    "We chose the `freight_value` column so we can perform a regression in order to try to find it's value based on all of the columns we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "222e2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VALUE = 'freight_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b762581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = df[TARGET_VALUE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b26f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         13.29\n",
       "1         19.93\n",
       "2         17.87\n",
       "3         12.79\n",
       "4         18.14\n",
       "          ...  \n",
       "118290    43.41\n",
       "118291    36.53\n",
       "118292    16.95\n",
       "118293     8.72\n",
       "118294    12.79\n",
       "Name: freight_value, Length: 118295, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67fb6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[TARGET_VALUE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005f0b8",
   "metadata": {},
   "source": [
    "## Separating prediction and test data\n",
    "\n",
    "We'll split our data in a 60/20/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "760b9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input \n",
    "train, val, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "# output\n",
    "train_labels, val_labels, test_labels = (\n",
    "    np.split(\n",
    "        target_col, \n",
    "        [int(.6*len(target_col)), int(.8*len(target_col))])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa6267b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting our initial df so we can free up some RAM\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b17f0b",
   "metadata": {},
   "source": [
    "# Picking 4 ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3d0e6",
   "metadata": {},
   "source": [
    "We'll use the following 4 algorithms:\n",
    "\n",
    "1. Linear regression\n",
    "2. Multilayer perceptron (a shallow one)\n",
    "3. random forests\n",
    "4. lightgbm/xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647da00",
   "metadata": {},
   "source": [
    "### Metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1ac53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate metrics\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf643db6",
   "metadata": {},
   "source": [
    "### Enabling MLFlow autologging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc0517aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "mlflow.tensorflow.autolog()\n",
    "mlflow.lightgbm.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8160d9",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "Let's start off with linear regression, which is the most simple algorithm in our selection, and will serve as a baseline for the following algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82ba2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(trial):\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "    with mlflow.start_run():\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(train, train_labels)\n",
    "\n",
    "        predictions = reg.predict(val)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
    "\n",
    "        # Print out model metrics\n",
    "        print(\"Linear regression model\")\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log mlflow attributes for mlflow UI\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        #mlflow.sklearn.log_model(reg, \"model\")\n",
    "        #modelpath = \"./mlflow/freight_value/model-linear-reg\"\n",
    "        #mlflow.sklearn.save_model(reg, modelpath)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d3d27c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 13:00:10,409]\u001b[0m A new study created in memory with name: no-name-a48463a4-b709-4ee6-835e-680b420e836a\u001b[0m\n",
      "\u001b[32m[I 2021-08-15 13:48:40,186]\u001b[0m Trial 0 finished with value: 10522467.054732079 and parameters: {}. Best is trial 0 with value: 10522467.054732079.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model\n",
      "  RMSE: 10522467.054732079\n",
      "  MAE: 829174.278560314\n",
      "  R2: -432433458073.49365\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(linear_regression, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a6d6a",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac5dfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(trial):\n",
    "    # hyper-parameters to test\n",
    "    params = {\n",
    "        \"hidden_units\": trial.suggest_int(\"hidden_units\", 3, 15),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n",
    "        \"epochs\": trial.suggest_int(\"epochs\", 10, 50)\n",
    "    }\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run():\n",
    "        normalizer = preprocessing.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(train))\n",
    "        \n",
    "        mlp_model = tf.keras.Sequential([\n",
    "            normalizer,\n",
    "            layers.Dense(units=params[\"hidden_units\"]),\n",
    "            layers.Dense(units=params[\"hidden_units\"]),\n",
    "            layers.Dense(units=params[\"hidden_units\"]),\n",
    "            layers.Dense(units=1),\n",
    "        ])\n",
    "\n",
    "        mlp_model.summary()\n",
    "        \n",
    "        mlp_model.compile(\n",
    "            optimizer=tf.optimizers.Adam(learning_rate=params[\"lr\"]),\n",
    "            loss='mean_squared_error'\n",
    "        )\n",
    "\n",
    "        history = mlp_model.fit(\n",
    "            train, train_labels,\n",
    "            validation_data=(test, test_labels),\n",
    "            epochs=params[\"epochs\"]\n",
    "        )\n",
    "        \n",
    "        predictions = mlp_model.predict(val)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
    "\n",
    "        # Print out model metrics\n",
    "        print(\"MLP model\")\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log mlflow attributes for mlflow UI\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.set_tags(\n",
    "            {\n",
    "                \"estimator_name\":\"MultiLayerPerceptron\",\n",
    "                \"estimator_class\":\"Keras\"\n",
    "            }\n",
    "        )\n",
    "        #mlflow.tensorflow.log_model(mlp_model, \"model\")\n",
    "        #modelpath = \"./mlflow/freight_value/model-mlp\"\n",
    "        #mlflow.tensorflow.save_model(mlp_model, modelpath)\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd5130",
   "metadata": {},
   "source": [
    "### Using optuna to optimize MLP's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d924f843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 13:48:40,193]\u001b[0m A new study created in memory with name: no-name-e6812a48-272e-41c7-9619-8305691fca36\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 132570    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 176,850\n",
      "Trainable params: 132,661\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "   2/2219 [..............................] - ETA: 6:59 - loss: 675.3687 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_begin` time: 0.0298s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0077s). Check your callbacks.\n",
      "2219/2219 [==============================] - 11s 4ms/step - loss: 628.7867 - val_loss: 28169172.0000\n",
      "Epoch 2/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 497.7792 - val_loss: 2194471.7500\n",
      "Epoch 3/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 320.2685 - val_loss: 106633960.0000\n",
      "Epoch 4/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 238.1416 - val_loss: 259586976.0000\n",
      "Epoch 5/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 226.6792 - val_loss: 427076544.0000\n",
      "Epoch 6/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 221.1996 - val_loss: 591050496.0000\n",
      "Epoch 7/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 217.5465 - val_loss: 713216384.0000\n",
      "Epoch 8/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 214.9025 - val_loss: 778483840.0000\n",
      "Epoch 9/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 213.1589 - val_loss: 849122368.0000\n",
      "Epoch 10/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 211.7312 - val_loss: 885093952.0000\n",
      "Epoch 11/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 210.8151 - val_loss: 974535488.0000\n",
      "Epoch 12/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.8352 - val_loss: 898361152.0000\n",
      "Epoch 13/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.3071 - val_loss: 980633664.0000\n",
      "Epoch 14/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.6918 - val_loss: 1037868800.0000\n",
      "Epoch 15/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.1748 - val_loss: 992183360.0000\n",
      "Epoch 16/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.7195 - val_loss: 837081088.0000\n",
      "Epoch 17/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.5685 - val_loss: 951456448.0000\n",
      "Epoch 18/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.2318 - val_loss: 1047518400.0000\n",
      "Epoch 19/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.8970 - val_loss: 928733824.0000\n",
      "Epoch 20/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.6774 - val_loss: 908746432.0000\n",
      "Epoch 21/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.4360 - val_loss: 906786112.0000\n",
      "Epoch 22/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.1498 - val_loss: 880063936.0000\n",
      "Epoch 23/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.9667 - val_loss: 784691648.0000\n",
      "Epoch 24/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.8940 - val_loss: 820957376.0000\n",
      "Epoch 25/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.7295 - val_loss: 797831808.0000\n",
      "Epoch 26/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.5174 - val_loss: 879497792.0000\n",
      "Epoch 27/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.4074 - val_loss: 820943424.0000\n",
      "Epoch 28/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.2336 - val_loss: 742708992.0000\n",
      "Epoch 29/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.2055 - val_loss: 806244736.0000\n",
      "Epoch 30/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.9854 - val_loss: 796218560.0000\n",
      "Epoch 31/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.8146 - val_loss: 694927616.0000\n",
      "Epoch 32/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.7877 - val_loss: 792689152.0000\n",
      "Epoch 33/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.6578 - val_loss: 780112896.0000\n",
      "Epoch 34/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.5970 - val_loss: 826635904.0000\n",
      "Epoch 35/35\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.5968 - val_loss: 718507264.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpsh4jcu_4/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 13:53:14,323]\u001b[0m Trial 0 finished with value: 29070.070794112642 and parameters: {'hidden_units': 6, 'lr': 0.00013783166250126664, 'epochs': 35}. Best is trial 0 with value: 29070.070794112642.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model\n",
      "  RMSE: 29070.070794112642\n",
      "  MAE: 5329.234663779358\n",
      "  R2: -3300473.017016375\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 198855    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 243,234\n",
      "Trainable params: 199,045\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/28\n",
      "   3/2219 [..............................] - ETA: 3:49 - loss: 801.4820WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_begin` time: 0.0212s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0124s). Check your callbacks.\n",
      "2219/2219 [==============================] - 12s 5ms/step - loss: 644.7246 - val_loss: 10571800.0000\n",
      "Epoch 2/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 583.9402 - val_loss: 2887801.5000\n",
      "Epoch 3/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 491.5643 - val_loss: 48720608.0000\n",
      "Epoch 4/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 363.8340 - val_loss: 223539776.0000\n",
      "Epoch 5/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 266.2116 - val_loss: 566851968.0000\n",
      "Epoch 6/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 229.3664 - val_loss: 699316224.0000\n",
      "Epoch 7/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 221.8483 - val_loss: 868506624.0000\n",
      "Epoch 8/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 218.5087 - val_loss: 921133184.0000\n",
      "Epoch 9/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 215.8385 - val_loss: 1176359424.0000\n",
      "Epoch 10/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 213.6086 - val_loss: 1246732672.0000\n",
      "Epoch 11/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.0431 - val_loss: 1481074304.0000\n",
      "Epoch 12/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 210.6841 - val_loss: 1402247040.0000\n",
      "Epoch 13/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.5800 - val_loss: 1578028160.0000\n",
      "Epoch 14/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.7311 - val_loss: 1597614080.0000\n",
      "Epoch 15/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.9581 - val_loss: 1626620032.0000\n",
      "Epoch 16/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.4653 - val_loss: 1725569920.0000\n",
      "Epoch 17/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.8259 - val_loss: 1628946688.0000\n",
      "Epoch 18/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.4911 - val_loss: 1721556992.0000\n",
      "Epoch 19/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.1174 - val_loss: 1791025408.0000\n",
      "Epoch 20/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.7678 - val_loss: 1698547200.0000\n",
      "Epoch 21/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.4862 - val_loss: 1719825280.0000\n",
      "Epoch 22/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.1882 - val_loss: 1745001600.0000\n",
      "Epoch 23/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.0156 - val_loss: 1718277120.0000\n",
      "Epoch 24/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.8733 - val_loss: 1742909952.0000\n",
      "Epoch 25/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.6250 - val_loss: 1753510016.0000\n",
      "Epoch 26/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.5232 - val_loss: 1818521472.0000\n",
      "Epoch 27/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.3336 - val_loss: 1717468160.0000\n",
      "Epoch 28/28\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.1115 - val_loss: 1829371776.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmphebzdi7j/model/data/model/assets\n",
      "MLP model\n",
      "  RMSE: 45358.496752358995\n",
      "  MAE: 8258.331527878088\n",
      "  R2: -8035286.961372626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 13:57:24,403]\u001b[0m Trial 1 finished with value: 45358.496752358995 and parameters: {'hidden_units': 9, 'lr': 6.593713512987263e-05, 'epochs': 28}. Best is trial 0 with value: 29070.070794112642.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 66285     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 110,502\n",
      "Trainable params: 66,313\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/49\n",
      "   3/2219 [..............................] - ETA: 3:26 - loss: 575.3996WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_begin` time: 0.0196s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0105s). Check your callbacks.\n",
      "2219/2219 [==============================] - 9s 4ms/step - loss: 651.2619 - val_loss: 137071344.0000\n",
      "Epoch 2/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 636.1483 - val_loss: 137172960.0000\n",
      "Epoch 3/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 626.1846 - val_loss: 167437040.0000\n",
      "Epoch 4/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 613.9304 - val_loss: 251334096.0000\n",
      "Epoch 5/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 598.1443 - val_loss: 429924640.0000\n",
      "Epoch 6/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 578.5332 - val_loss: 738949440.0000\n",
      "Epoch 7/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 554.9541 - val_loss: 1244908544.0000\n",
      "Epoch 8/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 527.9559 - val_loss: 1981438720.0000\n",
      "Epoch 9/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 498.3110 - val_loss: 2988200192.0000\n",
      "Epoch 10/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 467.0229 - val_loss: 4253036032.0000\n",
      "Epoch 11/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 434.4753 - val_loss: 5847448576.0000\n",
      "Epoch 12/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 401.3236 - val_loss: 7773432320.0000\n",
      "Epoch 13/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 368.6291 - val_loss: 9940514816.0000\n",
      "Epoch 14/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 337.4093 - val_loss: 12327683072.0000\n",
      "Epoch 15/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 308.3184 - val_loss: 14836670464.0000\n",
      "Epoch 16/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 282.3920 - val_loss: 17364705280.0000\n",
      "Epoch 17/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 260.6027 - val_loss: 19689095168.0000\n",
      "Epoch 18/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 243.6829 - val_loss: 21507332096.0000\n",
      "Epoch 19/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 231.1997 - val_loss: 22803736576.0000\n",
      "Epoch 20/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 222.6411 - val_loss: 23452616704.0000\n",
      "Epoch 21/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 216.9446 - val_loss: 23707211776.0000\n",
      "Epoch 22/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 213.1695 - val_loss: 23622733824.0000\n",
      "Epoch 23/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 210.6571 - val_loss: 23470858240.0000\n",
      "Epoch 24/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.8126 - val_loss: 23221024768.0000\n",
      "Epoch 25/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.4377 - val_loss: 22998798336.0000\n",
      "Epoch 26/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.4066 - val_loss: 22800863232.0000\n",
      "Epoch 27/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.6100 - val_loss: 22657087488.0000\n",
      "Epoch 28/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.9547 - val_loss: 22524495872.0000\n",
      "Epoch 29/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.4348 - val_loss: 22461636608.0000\n",
      "Epoch 30/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.0294 - val_loss: 22378008576.0000\n",
      "Epoch 31/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.6611 - val_loss: 22391793664.0000\n",
      "Epoch 32/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.3888 - val_loss: 22365515776.0000\n",
      "Epoch 33/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.1123 - val_loss: 22311874560.0000\n",
      "Epoch 34/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 202.8961 - val_loss: 22285285376.0000\n",
      "Epoch 35/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 202.7050 - val_loss: 22270464000.0000\n",
      "Epoch 36/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 202.5695 - val_loss: 22282862592.0000\n",
      "Epoch 37/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 202.4238 - val_loss: 22344386560.0000\n",
      "Epoch 38/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 202.2791 - val_loss: 22347098112.0000\n",
      "Epoch 39/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 202.2061 - val_loss: 22333450240.0000\n",
      "Epoch 40/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 202.0753 - val_loss: 22353360896.0000\n",
      "Epoch 41/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 201.9742 - val_loss: 22390829056.0000\n",
      "Epoch 42/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 201.9013 - val_loss: 22375720960.0000\n",
      "Epoch 43/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 201.8632 - val_loss: 22462181376.0000\n",
      "Epoch 44/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 201.7392 - val_loss: 22450812928.0000\n",
      "Epoch 45/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 201.7075 - val_loss: 22506715136.0000\n",
      "Epoch 46/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 201.6227 - val_loss: 22472464384.0000\n",
      "Epoch 47/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 201.5578 - val_loss: 22508261376.0000\n",
      "Epoch 48/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 201.5169 - val_loss: 22539728896.0000\n",
      "Epoch 49/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 201.4642 - val_loss: 22601762816.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmph7n6iwk9/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 14:03:35,261]\u001b[0m Trial 2 finished with value: 151125.27687811205 and parameters: {'hidden_units': 3, 'lr': 2.097040663215729e-05, 'epochs': 49}. Best is trial 0 with value: 29070.070794112642.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model\n",
      "  RMSE: 151125.27687811205\n",
      "  MAE: 27749.002557147298\n",
      "  R2: -89198664.79674345\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                243045    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 287,510\n",
      "Trainable params: 243,321\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "   3/2219 [..............................] - ETA: 3:45 - loss: 749.0275WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_begin` time: 0.0196s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0134s). Check your callbacks.\n",
      "2219/2219 [==============================] - 9s 4ms/step - loss: 338.1356 - val_loss: 32908058.0000\n",
      "Epoch 2/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 246.9527 - val_loss: 26203902.0000\n",
      "Epoch 3/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 237.3553 - val_loss: 25036566.0000\n",
      "Epoch 4/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 229.2770 - val_loss: 38800436.0000\n",
      "Epoch 5/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 225.3082 - val_loss: 32376218.0000\n",
      "Epoch 6/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 221.9786 - val_loss: 114168408.0000\n",
      "Epoch 7/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 220.0819 - val_loss: 54969072.0000\n",
      "Epoch 8/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 218.6768 - val_loss: 56154904.0000\n",
      "Epoch 9/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 217.6329 - val_loss: 43263924.0000\n",
      "Epoch 10/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 216.2656 - val_loss: 41698528.0000\n",
      "Epoch 11/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 215.5602 - val_loss: 64064852.0000\n",
      "Epoch 12/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 214.5324 - val_loss: 82069424.0000\n",
      "Epoch 13/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 213.7993 - val_loss: 71964328.0000\n",
      "Epoch 14/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.6210 - val_loss: 103334256.0000\n",
      "Epoch 15/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.7243 - val_loss: 102654808.0000\n",
      "Epoch 16/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.3744 - val_loss: 112144616.0000\n",
      "Epoch 17/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 211.5817 - val_loss: 58273056.0000\n",
      "Epoch 18/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 211.0267 - val_loss: 100157016.0000\n",
      "Epoch 19/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 210.4322 - val_loss: 58574564.0000\n",
      "Epoch 20/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 210.3903 - val_loss: 77792400.0000\n",
      "Epoch 21/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.6831 - val_loss: 57652240.0000\n",
      "Epoch 22/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.7551 - val_loss: 72383352.0000\n",
      "Epoch 23/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.3521 - val_loss: 72694968.0000\n",
      "Epoch 24/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.0219 - val_loss: 96870192.0000\n",
      "Epoch 25/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.3825 - val_loss: 83423504.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwcief6fu/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 14:06:55,356]\u001b[0m Trial 3 finished with value: 9273.360933062278 and parameters: {'hidden_units': 11, 'lr': 0.0009227598608909978, 'epochs': 25}. Best is trial 3 with value: 9273.360933062278.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model\n",
      "  RMSE: 9273.360933062278\n",
      "  MAE: 1782.856692734742\n",
      "  R2: -335859.14126271976\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 110475    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 154,730\n",
      "Trainable params: 110,541\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "   3/2219 [..............................] - ETA: 3:25 - loss: 541.8060WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_begin` time: 0.0199s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0103s). Check your callbacks.\n",
      "2219/2219 [==============================] - 9s 4ms/step - loss: 673.2737 - val_loss: 425146784.0000\n",
      "Epoch 2/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 639.3127 - val_loss: 326832736.0000\n",
      "Epoch 3/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 625.5999 - val_loss: 291588448.0000\n",
      "Epoch 4/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 610.9986 - val_loss: 317742784.0000\n",
      "Epoch 5/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 593.9811 - val_loss: 415596320.0000\n",
      "Epoch 6/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 573.5430 - val_loss: 606383360.0000\n",
      "Epoch 7/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 549.3313 - val_loss: 921399744.0000\n",
      "Epoch 8/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 521.4047 - val_loss: 1403344640.0000\n",
      "Epoch 9/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 489.7539 - val_loss: 2123444864.0000\n",
      "Epoch 10/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 455.0897 - val_loss: 3121158656.0000\n",
      "Epoch 11/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 418.0116 - val_loss: 4473738240.0000\n",
      "Epoch 12/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 379.8967 - val_loss: 6249574912.0000\n",
      "Epoch 13/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 341.8148 - val_loss: 8490967040.0000\n",
      "Epoch 14/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 306.1419 - val_loss: 11132810240.0000\n",
      "Epoch 15/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 275.0745 - val_loss: 13985986560.0000\n",
      "Epoch 16/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 250.4554 - val_loss: 16689626112.0000\n",
      "Epoch 17/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 233.1461 - val_loss: 18812549120.0000\n",
      "Epoch 18/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 222.2454 - val_loss: 20134254592.0000\n",
      "Epoch 19/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 215.9459 - val_loss: 20679544832.0000\n",
      "Epoch 20/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.2801 - val_loss: 20789346304.0000\n",
      "Epoch 21/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.9135 - val_loss: 20765087744.0000\n",
      "Epoch 22/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.2684 - val_loss: 20646948864.0000\n",
      "Epoch 23/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.0600 - val_loss: 20499169280.0000\n",
      "Epoch 24/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.1830 - val_loss: 20466436096.0000\n",
      "Epoch 25/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.4633 - val_loss: 20409780224.0000\n",
      "Epoch 26/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.9237 - val_loss: 20378081280.0000\n",
      "Epoch 27/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.5157 - val_loss: 20326332416.0000\n",
      "Epoch 28/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.1352 - val_loss: 20404602880.0000\n",
      "Epoch 29/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.8367 - val_loss: 20423563264.0000\n",
      "Epoch 30/30\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.6002 - val_loss: 20373657600.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpu_ijgq0k/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 14:10:49,679]\u001b[0m Trial 4 finished with value: 145372.27099876106 and parameters: {'hidden_units': 5, 'lr': 1.8466579518334734e-05, 'epochs': 30}. Best is trial 3 with value: 9273.360933062278.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model\n",
      "  RMSE: 145372.27099876106\n",
      "  MAE: 26760.511192538313\n",
      "  R2: -82536734.82604657\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 88380     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 132,614\n",
      "Trainable params: 88,425\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "   3/2219 [..............................] - ETA: 3:37 - loss: 646.8295WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_begin` time: 0.0194s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0127s). Check your callbacks.\n",
      "2219/2219 [==============================] - 9s 4ms/step - loss: 440.5571 - val_loss: 1662533.5000\n",
      "Epoch 2/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 246.2409 - val_loss: 1210404.1250\n",
      "Epoch 3/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 241.4418 - val_loss: 19724946.0000\n",
      "Epoch 4/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 230.7485 - val_loss: 36365900.0000\n",
      "Epoch 5/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 223.8776 - val_loss: 93534640.0000\n",
      "Epoch 6/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 219.6391 - val_loss: 51511844.0000\n",
      "Epoch 7/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 217.6627 - val_loss: 61732548.0000\n",
      "Epoch 8/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 215.7052 - val_loss: 68963576.0000\n",
      "Epoch 9/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 214.6354 - val_loss: 88645760.0000\n",
      "Epoch 10/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 213.4585 - val_loss: 54153228.0000\n",
      "Epoch 11/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.5588 - val_loss: 46458184.0000\n",
      "Epoch 12/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 211.8368 - val_loss: 79276056.0000\n",
      "Epoch 13/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 211.5205 - val_loss: 60274756.0000\n",
      "Epoch 14/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 211.0689 - val_loss: 60227376.0000\n",
      "Epoch 15/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 210.5957 - val_loss: 88788528.0000\n",
      "Epoch 16/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 210.1040 - val_loss: 80118856.0000\n",
      "Epoch 17/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.9016 - val_loss: 62720276.0000\n",
      "Epoch 18/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.4371 - val_loss: 78018816.0000\n",
      "Epoch 19/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.0936 - val_loss: 66506596.0000\n",
      "Epoch 20/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.9186 - val_loss: 55714768.0000\n",
      "Epoch 21/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.7338 - val_loss: 85699632.0000\n",
      "Epoch 22/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.3496 - val_loss: 53388828.0000\n",
      "Epoch 23/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.2394 - val_loss: 69297968.0000\n",
      "Epoch 24/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.6391 - val_loss: 62268132.0000\n",
      "Epoch 25/25\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.7522 - val_loss: 69086256.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmphommrctf/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 14:14:09,425]\u001b[0m Trial 5 finished with value: 8578.914172656961 and parameters: {'hidden_units': 4, 'lr': 0.0007616910471088858, 'epochs': 25}. Best is trial 5 with value: 8578.914172656961.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model\n",
      "  RMSE: 8578.914172656961\n",
      "  MAE: 1564.2424523670736\n",
      "  R2: -287440.0464267149\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                243045    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 287,510\n",
      "Trainable params: 243,321\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "   3/2219 [..............................] - ETA: 3:39 - loss: 771.3994WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_begin` time: 0.0194s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0128s). Check your callbacks.\n",
      "2219/2219 [==============================] - 9s 4ms/step - loss: 354.9859 - val_loss: 15557741.0000\n",
      "Epoch 2/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 245.9816 - val_loss: 70672840.0000\n",
      "Epoch 3/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 236.0881 - val_loss: 56450040.0000\n",
      "Epoch 4/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 228.4883 - val_loss: 55506036.0000\n",
      "Epoch 5/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 224.3367 - val_loss: 65282660.0000\n",
      "Epoch 6/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 221.3558 - val_loss: 79318568.0000\n",
      "Epoch 7/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 219.5899 - val_loss: 81338640.0000\n",
      "Epoch 8/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 217.9727 - val_loss: 51841072.0000\n",
      "Epoch 9/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 216.6478 - val_loss: 45811004.0000\n",
      "Epoch 10/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 215.8379 - val_loss: 68550792.0000\n",
      "Epoch 11/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 215.2450 - val_loss: 48229472.0000\n",
      "Epoch 12/12\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 214.1742 - val_loss: 69893856.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpe2llvum2/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 14:16:00,255]\u001b[0m Trial 6 finished with value: 8939.52775311599 and parameters: {'hidden_units': 11, 'lr': 0.0007082725917421973, 'epochs': 12}. Best is trial 5 with value: 8578.914172656961.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model\n",
      "  RMSE: 8939.52775311599\n",
      "  MAE: 1619.947932606869\n",
      "  R2: -312113.0314446522\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                265140    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 309,654\n",
      "Trainable params: 265,465\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/23\n",
      "   3/2219 [..............................] - ETA: 3:25 - loss: 665.7868WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_begin` time: 0.0195s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0108s). Check your callbacks.\n",
      "2219/2219 [==============================] - 9s 4ms/step - loss: 591.9612 - val_loss: 36835552.0000\n",
      "Epoch 2/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 324.7061 - val_loss: 58183596.0000\n",
      "Epoch 3/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 238.1588 - val_loss: 151481632.0000\n",
      "Epoch 4/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 228.8639 - val_loss: 296627712.0000\n",
      "Epoch 5/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 222.3941 - val_loss: 371747040.0000\n",
      "Epoch 6/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 218.6433 - val_loss: 441411904.0000\n",
      "Epoch 7/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 216.2653 - val_loss: 578218816.0000\n",
      "Epoch 8/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 214.2360 - val_loss: 533957856.0000\n",
      "Epoch 9/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.9123 - val_loss: 365230656.0000\n",
      "Epoch 10/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.2231 - val_loss: 484880096.0000\n",
      "Epoch 11/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 211.3419 - val_loss: 499513120.0000\n",
      "Epoch 12/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 210.5609 - val_loss: 579629248.0000\n",
      "Epoch 13/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.9242 - val_loss: 573260800.0000\n",
      "Epoch 14/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.5509 - val_loss: 459422752.0000\n",
      "Epoch 15/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.0226 - val_loss: 451195072.0000\n",
      "Epoch 16/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.6053 - val_loss: 621966080.0000\n",
      "Epoch 17/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.3505 - val_loss: 583262848.0000\n",
      "Epoch 18/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.8372 - val_loss: 570396672.0000\n",
      "Epoch 19/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.6512 - val_loss: 474341728.0000\n",
      "Epoch 20/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.2589 - val_loss: 505978272.0000\n",
      "Epoch 21/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.3499 - val_loss: 589970880.0000\n",
      "Epoch 22/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.7243 - val_loss: 433310048.0000\n",
      "Epoch 23/23\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.7561 - val_loss: 455472832.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyju8p72y/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 14:19:05,099]\u001b[0m Trial 7 finished with value: 22629.200746911454 and parameters: {'hidden_units': 12, 'lr': 0.00015603515983063726, 'epochs': 23}. Best is trial 5 with value: 8578.914172656961.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model\n",
      "  RMSE: 22629.200746911454\n",
      "  MAE: 4114.311136843061\n",
      "  R2: -1999964.8019575395\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 154665    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 198,974\n",
      "Trainable params: 154,785\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/49\n",
      "   3/2219 [..............................] - ETA: 3:23 - loss: 1020.7332WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_begin` time: 0.0195s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0103s). Check your callbacks.\n",
      "2219/2219 [==============================] - 9s 4ms/step - loss: 667.5840 - val_loss: 642834560.0000\n",
      "Epoch 2/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 645.6541 - val_loss: 555366016.0000\n",
      "Epoch 3/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 637.8855 - val_loss: 500690112.0000\n",
      "Epoch 4/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 630.6335 - val_loss: 480919872.0000\n",
      "Epoch 5/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 623.3987 - val_loss: 490011104.0000\n",
      "Epoch 6/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 615.7379 - val_loss: 525380000.0000\n",
      "Epoch 7/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 607.3491 - val_loss: 585084288.0000\n",
      "Epoch 8/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 598.0494 - val_loss: 668210624.0000\n",
      "Epoch 9/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 587.7441 - val_loss: 773968576.0000\n",
      "Epoch 10/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 576.3829 - val_loss: 906461376.0000\n",
      "Epoch 11/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 564.0103 - val_loss: 1061599808.0000\n",
      "Epoch 12/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 550.6656 - val_loss: 1240932480.0000\n",
      "Epoch 13/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 536.5115 - val_loss: 1443591168.0000\n",
      "Epoch 14/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 521.5104 - val_loss: 1664400896.0000\n",
      "Epoch 15/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 505.8258 - val_loss: 1900190080.0000\n",
      "Epoch 16/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 489.4894 - val_loss: 2151654400.0000\n",
      "Epoch 17/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 472.6256 - val_loss: 2415062528.0000\n",
      "Epoch 18/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 455.3221 - val_loss: 2691043328.0000\n",
      "Epoch 19/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 437.6785 - val_loss: 2960088064.0000\n",
      "Epoch 20/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 419.8193 - val_loss: 3239561984.0000\n",
      "Epoch 21/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 401.9434 - val_loss: 3511122944.0000\n",
      "Epoch 22/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 384.1568 - val_loss: 3771313152.0000\n",
      "Epoch 23/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 366.5734 - val_loss: 4024102400.0000\n",
      "Epoch 24/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 349.4573 - val_loss: 4246946048.0000\n",
      "Epoch 25/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 332.9635 - val_loss: 4442813440.0000\n",
      "Epoch 26/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 317.3411 - val_loss: 4612744192.0000\n",
      "Epoch 27/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 302.7501 - val_loss: 4741352960.0000\n",
      "Epoch 28/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 289.3055 - val_loss: 4812625920.0000\n",
      "Epoch 29/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 277.1753 - val_loss: 4854679552.0000\n",
      "Epoch 30/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 266.4611 - val_loss: 4841586688.0000\n",
      "Epoch 31/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 257.1725 - val_loss: 4803250688.0000\n",
      "Epoch 32/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 249.3207 - val_loss: 4717916160.0000\n",
      "Epoch 33/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 242.8168 - val_loss: 4610188288.0000\n",
      "Epoch 34/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 237.5309 - val_loss: 4468441600.0000\n",
      "Epoch 35/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 233.3633 - val_loss: 4299856896.0000\n",
      "Epoch 36/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 229.9723 - val_loss: 4179119872.0000\n",
      "Epoch 37/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 227.2892 - val_loss: 4026044416.0000\n",
      "Epoch 38/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 225.1129 - val_loss: 3906181888.0000\n",
      "Epoch 39/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 223.3135 - val_loss: 3822072064.0000\n",
      "Epoch 40/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 221.7393 - val_loss: 3748356864.0000\n",
      "Epoch 41/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 220.3737 - val_loss: 3704472320.0000\n",
      "Epoch 42/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 219.1518 - val_loss: 3692401152.0000\n",
      "Epoch 43/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 218.0236 - val_loss: 3701897472.0000\n",
      "Epoch 44/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 216.9758 - val_loss: 3733184768.0000\n",
      "Epoch 45/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 215.9876 - val_loss: 3782496256.0000\n",
      "Epoch 46/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 215.0522 - val_loss: 3828144128.0000\n",
      "Epoch 47/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 214.1719 - val_loss: 3874998272.0000\n",
      "Epoch 48/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 213.3320 - val_loss: 3948675584.0000\n",
      "Epoch 49/49\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.5359 - val_loss: 4024347136.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpebiqs6kl/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 14:25:11,041]\u001b[0m Trial 8 finished with value: 67290.53372148509 and parameters: {'hidden_units': 7, 'lr': 1.0473562849069252e-05, 'epochs': 49}. Best is trial 5 with value: 8578.914172656961.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model\n",
      "  RMSE: 67290.53372148509\n",
      "  MAE: 12090.93651303665\n",
      "  R2: -17684470.49075366\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 22094)             44189     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 154665    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 198,974\n",
      "Trainable params: 154,785\n",
      "Non-trainable params: 44,189\n",
      "_________________________________________________________________\n",
      "Epoch 1/46\n",
      "   3/2219 [..............................] - ETA: 3:25 - loss: 737.3267WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_begin` time: 0.0192s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0109s). Check your callbacks.\n",
      "2219/2219 [==============================] - 9s 4ms/step - loss: 642.6337 - val_loss: 9732706.0000\n",
      "Epoch 2/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 573.1973 - val_loss: 29356014.0000\n",
      "Epoch 3/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 422.8967 - val_loss: 128242904.0000\n",
      "Epoch 4/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 275.4010 - val_loss: 247087584.0000\n",
      "Epoch 5/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 230.5333 - val_loss: 311712608.0000\n",
      "Epoch 6/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 223.5727 - val_loss: 416437184.0000\n",
      "Epoch 7/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 219.4264 - val_loss: 528225472.0000\n",
      "Epoch 8/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 216.3912 - val_loss: 604982912.0000\n",
      "Epoch 9/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 213.9613 - val_loss: 674552960.0000\n",
      "Epoch 10/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 212.4439 - val_loss: 729716288.0000\n",
      "Epoch 11/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 211.0281 - val_loss: 689838528.0000\n",
      "Epoch 12/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 210.0837 - val_loss: 760146624.0000\n",
      "Epoch 13/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 209.2726 - val_loss: 753794048.0000\n",
      "Epoch 14/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.5988 - val_loss: 839268032.0000\n",
      "Epoch 15/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 208.0312 - val_loss: 783736256.0000\n",
      "Epoch 16/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.6300 - val_loss: 884665280.0000\n",
      "Epoch 17/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 207.2479 - val_loss: 866932736.0000\n",
      "Epoch 18/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.9818 - val_loss: 881494464.0000\n",
      "Epoch 19/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.4009 - val_loss: 723658944.0000\n",
      "Epoch 20/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 206.2726 - val_loss: 948205568.0000\n",
      "Epoch 21/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.9211 - val_loss: 749029504.0000\n",
      "Epoch 22/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.8742 - val_loss: 774159616.0000\n",
      "Epoch 23/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.6765 - val_loss: 881568832.0000\n",
      "Epoch 24/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.5388 - val_loss: 885458112.0000\n",
      "Epoch 25/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.2133 - val_loss: 848333568.0000\n",
      "Epoch 26/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 205.1348 - val_loss: 845936704.0000\n",
      "Epoch 27/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.7406 - val_loss: 726549248.0000\n",
      "Epoch 28/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.9000 - val_loss: 816620032.0000\n",
      "Epoch 29/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.6222 - val_loss: 880120320.0000\n",
      "Epoch 30/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.5594 - val_loss: 828404352.0000\n",
      "Epoch 31/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.4432 - val_loss: 810951040.0000\n",
      "Epoch 32/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.3504 - val_loss: 821210560.0000\n",
      "Epoch 33/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.1445 - val_loss: 758024128.0000\n",
      "Epoch 34/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 204.1227 - val_loss: 824168768.0000\n",
      "Epoch 35/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.9847 - val_loss: 792495488.0000\n",
      "Epoch 36/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.9872 - val_loss: 791000704.0000\n",
      "Epoch 37/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.7727 - val_loss: 746745856.0000\n",
      "Epoch 38/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.8163 - val_loss: 852379520.0000\n",
      "Epoch 39/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.6436 - val_loss: 811879808.0000\n",
      "Epoch 40/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.6554 - val_loss: 761603392.0000\n",
      "Epoch 41/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.5473 - val_loss: 830621376.0000\n",
      "Epoch 42/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.5132 - val_loss: 750216064.0000\n",
      "Epoch 43/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.4906 - val_loss: 833105984.0000\n",
      "Epoch 44/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.3603 - val_loss: 755421568.0000\n",
      "Epoch 45/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.3029 - val_loss: 761362240.0000\n",
      "Epoch 46/46\n",
      "2219/2219 [==============================] - 7s 3ms/step - loss: 203.3554 - val_loss: 866061184.0000\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpheht6tar/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 14:30:56,392]\u001b[0m Trial 9 finished with value: 30724.261575992754 and parameters: {'hidden_units': 7, 'lr': 0.00011209682434636478, 'epochs': 46}. Best is trial 5 with value: 8578.914172656961.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model\n",
      "  RMSE: 30724.261575992754\n",
      "  MAE: 5587.881144781618\n",
      "  R2: -3686777.5077823913\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(mlp, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b307794",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fd6df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 5),\n",
    "    }\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        rf = RandomForestRegressor(\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            min_samples_split=params[\"min_samples_split\"],\n",
    "            random_state=0\n",
    "        )\n",
    "        rf.fit(train, train_labels)\n",
    "        \n",
    "        predictions = rf.predict(val)\n",
    "        \n",
    "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
    "        \n",
    "        print(\"Random Forest model\")\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "        \n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_params(trial.params)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fcbca4",
   "metadata": {},
   "source": [
    "### Using optuna to optimize Random Forest's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0616b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 14:30:56,404]\u001b[0m A new study created in memory with name: no-name-538256ab-8067-462e-b0d8-20241441c7cb\u001b[0m\n",
      "\u001b[32m[I 2021-08-15 14:55:07,954]\u001b[0m Trial 0 finished with value: 16.01800413886942 and parameters: {'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 0 with value: 16.01800413886942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.01800413886942\n",
      "  MAE: 8.763791506249913\n",
      "  R2: -0.0020766497823212493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 15:03:32,842]\u001b[0m Trial 1 finished with value: 16.00618181870716 and parameters: {'n_estimators': 60, 'max_depth': 4, 'min_samples_split': 4}. Best is trial 1 with value: 16.00618181870716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.00618181870716\n",
      "  MAE: 8.766755456279734\n",
      "  R2: -0.0005980012564812398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 15:09:10,070]\u001b[0m Trial 2 finished with value: 16.004510507402266 and parameters: {'n_estimators': 52, 'max_depth': 3, 'min_samples_split': 4}. Best is trial 2 with value: 16.004510507402266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.004510507402266\n",
      "  MAE: 8.767637353258664\n",
      "  R2: -0.0003890540557585087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 15:27:57,379]\u001b[0m Trial 3 finished with value: 16.009817491732 and parameters: {'n_estimators': 110, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 2 with value: 16.004510507402266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.009817491732\n",
      "  MAE: 8.767908043798007\n",
      "  R2: -0.0010526081523261066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 15:52:24,326]\u001b[0m Trial 4 finished with value: 16.018543658213876 and parameters: {'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 2 with value: 16.004510507402266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.018543658213876\n",
      "  MAE: 8.764184076726282\n",
      "  R2: -0.0021441549268359505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 16:12:57,097]\u001b[0m Trial 5 finished with value: 16.007022061868554 and parameters: {'n_estimators': 149, 'max_depth': 4, 'min_samples_split': 3}. Best is trial 2 with value: 16.004510507402266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.007022061868554\n",
      "  MAE: 8.767472594139605\n",
      "  R2: -0.0007030566288142026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 16:38:02,361]\u001b[0m Trial 6 finished with value: 16.012359364315188 and parameters: {'n_estimators': 123, 'max_depth': 6, 'min_samples_split': 3}. Best is trial 2 with value: 16.004510507402266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.012359364315188\n",
      "  MAE: 8.766966330425877\n",
      "  R2: -0.0013705068640099682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 17:11:44,094]\u001b[0m Trial 7 finished with value: 16.023377669128543 and parameters: {'n_estimators': 112, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 2 with value: 16.004510507402266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.023377669128543\n",
      "  MAE: 8.767897510034356\n",
      "  R2: -0.002749092160128752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 17:35:59,234]\u001b[0m Trial 8 finished with value: 16.009428236186576 and parameters: {'n_estimators': 142, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 2 with value: 16.004510507402266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.009428236186576\n",
      "  MAE: 8.767004935778605\n",
      "  R2: -0.0010039304528941528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 17:46:42,480]\u001b[0m Trial 9 finished with value: 16.007012685276973 and parameters: {'n_estimators': 62, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 2 with value: 16.004510507402266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model\n",
      "  RMSE: 16.007012685276973\n",
      "  MAE: 8.76435357727949\n",
      "  R2: -0.0007018842457098273\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(random_forest, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872d6a3",
   "metadata": {},
   "source": [
    "## Gradient Boosting with LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6c47a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 25, 35),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    }\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        model = LGBMRegressor(\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            num_leaves=params[\"num_leaves\"],\n",
    "        )\n",
    "        model.fit(train, train_labels)\n",
    "        \n",
    "        predictions = model.predict(test)\n",
    "        print('Prediction: %.3f' % predictions[0])\n",
    "        \n",
    "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
    "\n",
    "        print(\"LGBM model\")\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log mlflow attributes for mlflow UI\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.set_tags(\n",
    "            {\n",
    "                \"estimator_class\":\"LightGBM\",\n",
    "                \"estimator_name\":\"Gradient Boosting\"\n",
    "            }\n",
    "        )\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19013283",
   "metadata": {},
   "source": [
    "### Using optuna to optimize Gradient Boosting's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "302c2818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-15 17:46:42,488]\u001b[0m A new study created in memory with name: no-name-1911296e-828b-41a8-bd2b-892cb54c52f7\u001b[0m\n",
      "\u001b[33m[W 2021-08-15 17:46:55,907]\u001b[0m Trial 0 failed because of the following error: LightGBMError('Do not support special JSON characters in feature name.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/igor/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-25-fce15f02147c>\", line 17, in gradient_boosting\n",
      "    model.fit(train, train_labels)\n",
      "  File \"/usr/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 818, in fit\n",
      "    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n",
      "  File \"/usr/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 683, in fit\n",
      "    self._Booster = train(params, train_set,\n",
      "  File \"/usr/lib/python3.9/site-packages/lightgbm/engine.py\", line 228, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/usr/lib/python3.9/site-packages/lightgbm/basic.py\", line 2229, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/usr/lib/python3.9/site-packages/lightgbm/basic.py\", line 1468, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/usr/lib/python3.9/site-packages/lightgbm/basic.py\", line 1298, in _lazy_init\n",
      "    return self.set_feature_name(feature_name)\n",
      "  File \"/usr/lib/python3.9/site-packages/lightgbm/basic.py\", line 1780, in set_feature_name\n",
      "    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(\n",
      "  File \"/usr/lib/python3.9/site-packages/lightgbm/basic.py\", line 110, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Do not support special JSON characters in feature name.\u001b[0m\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Do not support special JSON characters in feature name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5f2171f33d2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_boosting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-fce15f02147c>\u001b[0m in \u001b[0;36mgradient_boosting\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mnum_leaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_leaves\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         )\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    816\u001b[0m             callbacks=None, init_model=None):\n\u001b[1;32m    817\u001b[0m         \u001b[0;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n\u001b[0m\u001b[1;32m    819\u001b[0m                     \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[1;32m    684\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2227\u001b[0m                 )\n\u001b[1;32m   2228\u001b[0m             \u001b[0;31m# construct booster object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2229\u001b[0;31m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2230\u001b[0m             \u001b[0;31m# copy the parameters from train_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1466\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m                 \u001b[0;31m# create train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m                 self._lazy_init(self.data, label=self.label,\n\u001b[0m\u001b[1;32m   1469\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Wrong predictor type {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0;31m# set feature names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_feature_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init_from_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mset_feature_name\u001b[0;34m(self, feature_name)\u001b[0m\n\u001b[1;32m   1778\u001b[0m                                  .format(len(feature_name), self.num_feature()))\n\u001b[1;32m   1779\u001b[0m             \u001b[0mc_feature_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m             _safe_call(_LIB.LGBM_DatasetSetFeatureNames(\n\u001b[0m\u001b[1;32m   1781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_feature_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Do not support special JSON characters in feature name."
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(gradient_boosting, n_trials=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
