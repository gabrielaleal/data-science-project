{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c781e0",
   "metadata": {},
   "source": [
    "## Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('project1_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0bc65",
   "metadata": {},
   "source": [
    "#### Converting cols to their appropriate types again because we lost it on the csv export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbdbe54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"product_category_name\"] = df[\"product_category_name\"].astype('category')\n",
    "df[\"order_status\"] = df[\"order_status\"].astype('category')\n",
    "df[\"review_score\"] = df[\"review_score\"].astype('category')\n",
    "df[\"payment_type\"] = df[\"payment_type\"].astype('category')\n",
    "df[\"customer_zip_code_prefix\"] = df[\"customer_zip_code_prefix\"].astype('category')\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype('category')\n",
    "df[\"customer_state\"] = df[\"customer_state\"].astype('category')\n",
    "df[\"seller_zip_code_prefix\"] = df[\"seller_zip_code_prefix\"].astype('category')\n",
    "df[\"seller_city\"] = df[\"seller_city\"].astype('category')\n",
    "df[\"seller_state\"] = df[\"seller_state\"].astype('category')\n",
    "\n",
    "df[\"product_name_lenght\"] = df[\"product_name_lenght\"].astype('int64')\n",
    "df[\"product_description_lenght\"] = df[\"product_description_lenght\"].astype('int64')\n",
    "df[\"product_photos_qty\"] = df[\"product_photos_qty\"].astype('int64')\n",
    "df[\"payment_installments\"] = df[\"payment_installments\"].astype('int64')\n",
    "df[\"payment_sequential\"] = df[\"payment_sequential\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bef45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d661d06",
   "metadata": {},
   "source": [
    "#### Droping unnecessary columns\n",
    "We only want to work with numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d9829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095deda2",
   "metadata": {},
   "source": [
    "We'll also drop the `payment_value` column because our model would simply infer our target value from it by subtracting it from the `price` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['payment_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ade1c",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "Here we'll one-hot encode all of our categorical columns, and then drop the original ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888fbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df = df.select_dtypes(exclude=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a976764",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87163958",
   "metadata": {},
   "source": [
    "Even though we generated over 22000 columns this way, we believe that our model will be powerful enough to filter out any unecessary data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf542d7f",
   "metadata": {},
   "source": [
    "## Picking column for prediction\n",
    "\n",
    "We chose the `freight_value` column so we can perform a regression in order to try to find it's value based on all of the columns we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VALUE = 'freight_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = df[TARGET_VALUE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b26f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[TARGET_VALUE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005f0b8",
   "metadata": {},
   "source": [
    "## Separating prediction and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e5692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll define a random_state in order to have a reproducible split across runs\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target_col, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b17f0b",
   "metadata": {},
   "source": [
    "# Picking 4 ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3d0e6",
   "metadata": {},
   "source": [
    "We'll use the following 4 algorithms:\n",
    "\n",
    "1. Linear regression\n",
    "2. Multilayer perceptron (a shallow one)\n",
    "3. Multilayer perceptron (a deep one, AKA DNN)\n",
    "4. ?? (random forests or svm?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8160d9",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "Let's start off with linear regression, which is the most simple algorithm in our selection, and will serve as a baseline for the following algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06622cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42efe5",
   "metadata": {},
   "source": [
    "Since a regression model can be seen basicaly as a single unit, single layer MLP model, we'll create it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ce5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852da458",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f513add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(x_train) == len(y_train)\n",
    "len(x_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regression_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78d942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
